{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["from __future__ import unicode_literals\n","import os\n","from IPython.core.display import display, HTML\n","from IPython.display import display, Javascript, clear_output\n","from IPython.core.debugger import set_trace\n","\n","!pip install allensdk\n","clear_output()\n","!pip install joblib\n","clear_output()\n","!pip install --upgrade \"hbp-service-client==1.0.0\"\n","clear_output()\n","#!conda install -y -c r rpy2 \n","#!conda install -c r r-base -y\n","clear_output()\n","!pip install --upgrade sklearn\n","clear_output()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import sys\n","import os\n","import numpy as np\n","import scipy as sci\n","import csv\n","import pickle as pk\n","import h5py\n","import math as mt\n","import matplotlib.pyplot as plt\n","import matplotlib.axis as axis\n","import matplotlib\n","import matplotlib.legend as lgd\n","import sklearn.cluster as cluster\n","import glob\n","import six\n","import time as time\n","import json\n","import pandas as pd\n","import mcmodels.core as core\n","import mcmodels.models as models\n","import sklearn.decomposition as decomp\n","import sklearn.feature_selection as fs\n","import sklearn.linear_model as lm\n","import sklearn.metrics as metrics\n","import zipfile\n","import cortical_map_10 as cm\n","import nrrd\n","import rpy2.robjects as ro\n","import rpy2\n","import nibabel as nib\n","import base64\n","import nrrd\n","import skimage as ski\n","import imp \n","import io, os, sys, types\n","\n","from IPython import get_ipython\n","from nbformat import read\n","from IPython.core.interactiveshell import InteractiveShell\n","from sklearn import multioutput\n","from pandas.tools.plotting import table\n","from itertools import groupby\n","from sklearn.preprocessing import Imputer, normalize, StandardScaler, scale\n","from scipy.stats import boxcox, mstats, normaltest, pearsonr, skew, iqr\n","from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n","from sklearn.model_selection import cross_val_predict,\\\n","                                    GridSearchCV, KFold,\\\n","                                    permutation_test_score, \\\n","                                    StratifiedKFold, cross_val_score, RandomizedSearchCV\n","from sklearn.dummy import DummyClassifier, DummyRegressor\n","from sklearn.linear_model import RandomizedLogisticRegression,\\\n","                                 LogisticRegression,SGDClassifier, Ridge, Lars, ElasticNet\n","from sklearn.neural_network import MLPRegressor\n","from sets import Set\n","from sklearn import utils\n","from collections import OrderedDict\n","from joblib import Parallel, delayed\n","from scipy.ndimage.filters import laplace\n","from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache \n","from allensdk.api.queries.grid_data_api import GridDataApi\n","from scipy.ndimage.filters import laplace\n","from allensdk.api.queries.ontologies_api import OntologiesApi\n","from json import dumps as json_encode\n","from base64 import b64encode\n","from mcmodels.models.voxel import RegionalizedModel\n","from subprocess import call\n","\n","os.environ['KMP_DUPLICATE_LIB_OK']='True'"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Initially a series of data structures, files and functions that have to be utilized throughout the analysis have to be stored in the current directory space.  \n","The code bellow is responsible for downloading the aforementioned data from the storage space."]},{"metadata":{"trusted":true},"cell_type":"code","source":["import os\n","from IPython.display import clear_output\n","client      = get_bbp_client().document\n","collab_path = get_collab_storage_path()\n","ccp_path    = 'CCP v2'\n","itemlist = client.listdir(os.path.join(collab_path,ccp_path))\n","for element in itemlist:\n","    if os.path.isfile('./' + str(element)) == True: continue\n","    if 'Library.py' in element: continue\n","    print 'element {} has been downloaded'.format(element)\n","    local_path = './' + element\n","    client.download_file(os.path.join(collab_path,ccp_path, element),local_path)\n","    clear_output()"],"execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["from cfg import *"],"execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The functions and classes shown bellow (find_notebook, NotebookLoader, NotebookFinder) were taken from a tutorial on how to import external jupyter notebooks as modules.\n","Documentations about the aforementioned functions and classes can be found in this link:  \n","https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Importing%20Notebooks.html"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["def find_notebook(fullname, path=None):\n","    \"\"\"find a notebook, given its fully qualified name and an optional path\n","\n","    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n","    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n","    does not exist.\n","    \"\"\"\n","    name = fullname.rsplit('.', 1)[-1]\n","    if not path:\n","        path = ['']\n","    for d in path:\n","        nb_path = os.path.join(d, name + \".ipynb\")\n","        if os.path.isfile(nb_path):\n","            return nb_path\n","        # let import Notebook_Name find \"Notebook Name.ipynb\"\n","        nb_path = nb_path.replace(\"_\", \" \")\n","        if os.path.isfile(nb_path):\n","            return nb_path\n","\n","class NotebookLoader(object):\n","    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n","    def __init__(self, path=None):\n","        self.shell = InteractiveShell.instance()\n","        self.path = path\n","\n","    def load_module(self, fullname):\n","        \"\"\"import a notebook as a module\"\"\"\n","        path = find_notebook(fullname, self.path)\n","\n","        print (\"importing Jupyter notebook from %s\" % path)\n","\n","        # load the notebook object\n","        with io.open(path, 'r', encoding='utf-8') as f:\n","            nb = read(f, 4)\n","\n","\n","        # create the module and add it to sys.modules\n","        # if name in sys.modules:\n","        #    return sys.modules[name]\n","        mod = types.ModuleType(fullname)\n","        mod.__file__ = path\n","        mod.__loader__ = self\n","        mod.__dict__['get_ipython'] = get_ipython\n","        sys.modules[fullname] = mod\n","\n","        # extra work to ensure that magics that would affect the user_ns\n","        # actually affect the notebook module's ns\n","        save_user_ns = self.shell.user_ns\n","        self.shell.user_ns = mod.__dict__\n","\n","        try:\n","          for cell in nb.cells:\n","            if cell.cell_type == 'code':\n","                # transform the input to executable Python\n","                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n","                # run the code in themodule\n","                exec(code, mod.__dict__)\n","        finally:\n","            self.shell.user_ns = save_user_ns\n","        return mod\n","    \n","class NotebookFinder(object):\n","    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n","    def __init__(self):\n","        self.loaders = {}\n","\n","    def find_module(self, fullname, path=None):\n","        nb_path = find_notebook(fullname, path)\n","        if not nb_path:\n","            return\n","\n","        key = path\n","        if path:\n","            # lists aren't hashable\n","            key = os.path.sep.join(path)\n","\n","        if key not in self.loaders:\n","            self.loaders[key] = NotebookLoader(path)\n","        return self.loaders[key]   \n","    \n","sys.meta_path.append(NotebookFinder())    "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["In this step a series of libraries whose classes and functions have to be utilized throughout the analysis,  \n","are being downloaded from the storage space and imported as modules."]},{"metadata":{"trusted":true},"cell_type":"code","source":["elements = ['PrimaryLibrary.ipynb','SecondaryLibrary.ipynb','ParserLibrary.ipynb']\n","for element in elements:\n","    local_path = './' + element\n","    client.download_file(os.path.join(collab_path, element),local_path)\n","\n","import PrimaryLibrary as PL\n","imp.reload(PL)\n","\n","import SecondaryLibrary as SL\n","imp.reload(SL)\n","\n","import ParserLibrary as PrL\n","#imp.reload(PrL)\n","\n","clear_output()"],"execution_count":3,"outputs":[{"output_type":"stream","text":"importing Jupyter notebook from PrimaryLibrary.ipynb\nimporting Jupyter notebook from SecondaryLibrary.ipynb\nimporting Jupyter notebook from PrimaryLibrary.ipynb\nimporting Jupyter notebook from SecondaryLibrary.ipynb\nimporting Jupyter notebook from ParserLibrary.ipynb\n","name":"stdout"},{"output_type":"error","ename":"IOError","evalue":"Unable to open file (file signature not found)","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-3-94fb688183fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mParserLibrary\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mPrL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#imp.reload(PrL)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/jovyan/NotebookSearch.pyc\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# run the code in themodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/jovyan/ParserLibrary.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/home/jovyan/ParserLibrary.ipynb\u001b[0m in \u001b[0;36mParseAtlasData\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mIOError\u001b[0m: Unable to open file (file signature not found)"]}]},{"metadata":{},"cell_type":"markdown","source":["## Parameter Initialization"]},{"metadata":{},"cell_type":"markdown","source":["Initializing the parameters of the supervised learning models to be used.  \n","The models applied in this analysis are: \n","*   classification = Random Forest classifier, Logistic Regression classifier\n","*   regression     = Random Forest regressor,  Ridge regressor"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["tol_num = 0.001\n","\n","logreg_params = {'penalty': ['l2'], 'C' : np.logspace(-4, 1,base = 10), \\\n","            'solver': ['newton-cg','lbfgs','sag','liblinear','saga'], \\\n","            'class_weight' : ['balanced']}\n","\n","rfc_params = {'max_depth': [10, 60, 100, None],\n","             'max_features': ['auto', 'sqrt'],\n","             'min_samples_leaf': [1, 2, 4],\n","             'min_samples_split': [2, 5, 10],\n","             'n_estimators': [25,50,100,200],\\\n","             'criterion': ['gini'],\n","             'oob_score': [True], 'random_state' : [None],\\\n","             'max_features' : ['auto'], 'class_weight' : ['balanced']}\n","\n","ridge_params = {'alpha': [10e-4,10e-3,10e-2,0.5,1,2.5,5,7.5,10,100],\n","              'solver' : ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'saga'],\n","              'tol': [tol_num], 'max_iter' : [1000]}\n","\n","\n","sv_models = [GridSearchCV(LogisticRegression(), param_grid = logreg_params, scoring = 'f1', cv = 3, n_jobs = -1),\n","             GridSearchCV(RandomForestClassifier(), param_grid = rfc_params, scoring = 'f1', cv = 3, n_jobs = -1),\n","             DummyClassifier(),\n","             GridSearchCV(Ridge(), param_grid = ridge_params, \n","                          scoring = 'neg_mean_squared_error', \n","                          cv = 3, n_jobs = -1),\n","             RandomForestRegressor(n_estimators = 100),\n","             DummyRegressor()\n","            ]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Loading a series of data structures that will be used in the analysis.  \n","The data are being loaded for reasons of time efficiency.  \n","The Classes_and_Modules notebook provides comments and descriptions for the functions in which the data were created"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["leaves         = pk.load(open('leaf_nodes.pkl','rb'))\n","GeneExp        = h5py.File('G_Exp.hdf5', 'r')['dataset1']\n","GeneMeta       = pk.load(open('GeneMeta.pkl','r'))\n","GeneAcros      = np.asarray([val['genes'][0]['entrez_id'] for val in GeneMeta])\n","GeneNames      = np.asarray([val['genes'][0]['acronym'] for val in GeneMeta])\n","GeneMetaDict   = {val : GeneNames[idx] for idx,val in enumerate(GeneAcros)}\n","ConDict        = pk.load(open('CreLineDict.pkl','rb'))\n","folder_name    = 'Paper4/'\n","targetprofiles = OrderedDict()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Storage of information regarding the mouse brain structures.\n","The targetprofiles dictionary specializes in target areas \n","with regards to connectivity patterns in the mouse mesoconnectome.\n","Its keys are: \n","   *           str_acronym = acronyms of target areas/structures\n","   *           alt laminar profiles = laminar profiles of cortical structures\n","   *           father               = the brain regions in which each target belongs to      \n","   \n","   \n","The leaf_keys contain information about target areas that are present on the finest possible level of description.\n","For instance areas called VISp (primary visual area) and VISp l1 (primary visual area, layer 1) could both be found \n","in the dataset, and therefore the leaf_keys are being used to filter out VISp as a non-leaf key in the structure hierarchy\n","since a finer description is present (VISp l1)."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["with open('acr2parent.json', 'r') as fp:\n","     acr2parent = json.load(fp)\n","with open('structures.csv','rb') as fp:\n","     structure = SL.readtable(fp)\n","struct_idx_dict = {val:idx for idx,val in enumerate(structure['id'])}\n","targetprofiles['str_acronym'] = [val for val in structure['acronym']]\n","targetprofiles['alt laminar profiles'] = PL.LaminarRegistration(targetprofiles['str_acronym'])\n","# storing layer 1 and layer 4 related areas for a latter analysis\n","l4_vals = [idx for idx,val in enumerate(targetprofiles['alt laminar profiles']) if val == 'layer 4']\n","l1_vals = [idx for idx,val in enumerate(targetprofiles['alt laminar profiles']) if val == 'layer 1']\n","lam_to_idx = {val:targetprofiles['alt laminar profiles'][idx] for idx,val in enumerate(structure['id'])}\n","\n","# storage of leaf-level structures\n","leaf_keys = [int(val[0]) for val in leaves]  \n","\n","for key in targetprofiles.keys():\n","    targetprofiles[key] = [val for idx,val in enumerate(targetprofiles[key]) if idx in leaf_keys]\n","targetprofiles['father'] = []\n","for strut in targetprofiles['str_acronym']:\n","    father = [val for key,val in acr2parent.items() if key == strut]\n","    if father == []:\n","       targetprofiles['father'].append(strut) \n","    else:\n","       targetprofiles['father'].append(father[0])  "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The params dictionary stores information which will be used throughout the analysis.\n","It will be passed as a parameter through the functions and updated at various steps. "]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["params = {'alter' : None, 'fetch' : 'all', 'distance prior': False,\\\n","          'acronyms': targetprofiles['str_acronym'],\\\n","          'method': 'classification', 'leaf': True, \\\n","          'validation' : [StratifiedKFold(n_splits = 3, shuffle = True), KFold(n_splits = 3, shuffle = True)],\\\n","          'prefix': 'Paper4/', 'primary models': [i for i in sv_models], \\\n","          'Gene Acronyms Original': GeneAcros, 'Gene Metadata': GeneMetaDict,\n","          'leaf_keys' : leaf_keys}"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Conversion of the Gene Expression dataset as a numpy array for analysis,  \n","initialization of various dictionaries to store preprocessed data\n","and results per tracer category (driver line),  \n","and initialization the the MesoconnectomePredictor for its\n","functions to be utilized"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["GeneExp = np.asarray(GeneExp, dtype = np.float32)\n","ConStr_proc = {}; GeneExp_proc = {}; y = {}\n","\n","# matrix reduction to leaf-level structures\n","GeneExp  = GeneExp[leaf_keys,:]  \n","MesoPred = PL.MesoconnectomePredictor(GeneExp, ConDict['wild_type']['ConMat'])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Predictive Pipeline  \n","### Author: Nestor Timonidis\n","In our examples I utilize the unionized anatomical tract tracing data taken from the Allen Institute for Brain Science, as shown in the Class_and_Modules notebook. The data come in the form of a dictionary with nested matrices, where each dictionary corresponds to a tracer category like wild type or Syt6-Cre_KI148 cre-line experiments for instance.   \n","In order to demonstrate the MesoPred tool, a number of categories are selected as shown bellow. This analysis can take more than a day if run for all possible tracer categories. Therefore, for reasons of time efficiency one could skip this cell and move to the next one where the results can be loaded by stored pickle files."]},{"metadata":{},"cell_type":"markdown","source":["\n","In this pipeline a number of steps is being followed:  \n","0.  Selection of the tracer category (driver) of interest, reduction of tracing data to the leaf-level structures and storage of a number of parameters to be used in the analysis, such as the layer profiles and abbreviations of the target areas of the dataset.\n","1.  Preprocessing of the gene expression and tract tracing data. The function called in that step is PreProcessing\n","2.  Prediction with a logistic or linear ridge regression model using the cross-validation method for performance evaluation. The function called in that step is CustomCrossval.\n","3.  Prediction with a random forest classifier or regressor model using the cross-validation method for performance evaluation. The function called in that step is CustomCrossval.\n","4.  Prediction with a control (baseline) model using the cross-validation method for performance evaluation. The function called in that step is CustomCrossval.\n","5.  Storage of the predicted connectivity patterns, probability scores and gene importance (coefficient) scores per tracer in dictionaries stratified by the tested driver categories. The function called in that step is UnravelResults.\n","6.  Based on the stored connectivity patterns and the actual (ground truth) ones, evaluation of the predictive process with series of statistical measures. Examples include r squared and root mean squared error for regression, and f1-score and area under the roc curve for classification. The function called in that step is Evaluation.\n","8. Estimate the stability of the fittest model based on the optimal hyperparameters selected for each fold of the CustomCrossval function (step 3). In case that the model is considered as stable, then the model fits the whole data with the optimal hyperparameters"]},{"metadata":{"trusted":true},"cell_type":"code","source":["for key in ConDict.keys():\n","     \n","    ## Step 0:\n","    # measure used not to repeat predictions that have already been done\n","    outfile = key + '_all_results' \n","    if os.path.isfile('./' + outfile + '_ridge.pkl') == True: continue \n","    ConStr  = np.asarray(ConDict[key]['ConMat'], dtype = np.float32)\n","    ConStr = ConStr[leaf_keys,:]\n","    params['injection_number'] = np.shape(ConStr)[1]  \n","    params['cre-line'] = key\n","    params['structure-abbrev'] = ConDict[key]['structure-abbrev']\n","    params['layer'] = ConDict[key]['layer'][0]\n","    params['cell-type'] = ConDict[key]['cell-type'][0]\n","    params['method'] = 'regression'\n"," \n","    print 'Driver line: '+ str(key) + '\\nTracer number: ' + str(ConStr.shape[1]) \n","    \n","    ## Step 1:\n","    GeneExp_proc[key], ConStr_proc[key], y[key], sc_sqrt = MesoPred.PreProcessing(\n","                                                    GeneExp, ConStr, params)\n","    str_copy = np.delete(targetprofiles['str_acronym'],params['nanCons'],0); str_copy = np.delete(str_copy,params['nanGenes'],0)\n","  \n","    start = time.time()\n","    ## Step 2:\n","    print 'Ridge ' + params['method'] +  ' predictive phase ..'    \n","    ridge_pred  = list(SL.CustomCrossval(params['primary models'][3], GeneExp_proc[key], \n","                                         ConStr_proc[key], params['validation'][1]))\n","    ridge_pred.append(GeneExp_proc[key])\n","    #pk.dump(ridge_pred, open(params['cre-line'] + '_ridge_pred.pkl', 'wb'))\n","    print 'Ridge ' + params['method'] +  ' has been completed' \n","    \n","    ## Step 3:\n","    print 'Random forest ' + params['method'] + ' predictive phase ..'\n","    rf_pred  = list(SL.CustomCrossval(params['primary models'][4], GeneExp_proc[key], \n","                                      ConStr_proc[key], params['validation'][1]))\n","    rf_pred.append(GeneExp_proc[key])                                  \n","    #pk.dump(rf_pred, open(params['cre-line'] + '_rf_pred.pkl','wb'))\n","    print 'Random forest ' + params['method'] +  ' has been completed' \n","    \n","    ## Step 4:\n","    print 'Control model ' + params['method'] +  ' predictive phase ..'\n","    bl_pred  = list(SL.CustomCrossval(params['primary models'][5], GeneExp_proc[key], \n","                                      ConStr_proc[key], params['validation'][1]))\n","    bl_pred.append(GeneExp_proc[key])                                       \n","   \n","    #pk.dump(bl_pred, open(params['cre-line'] + '_bl_pred.pkl','wb'))\n","    print 'Control ' + params['method'] +  ' has been completed'  \n","    \n","    end = time.time() \n","    print  'Elapsed time: ' + str((end - start)/60)   \n","    \n","    ## Step 5:\n","    print 'Unraveling of results phase ..' \n","    ClfResults_ridge = MesoPred.UnravelResults(ridge_pred, params, sc_sqrt)\n","    ClfResults_rf = MesoPred.UnravelResults(rf_pred, params, sc_sqrt)\n","    #pk.dump(ClfResults_rf, open(outfile + '_rf.pkl','wb'))\n","    ClfResults_bl = MesoPred.UnravelResults(bl_pred, params, sc_sqrt)\n","    #pk.dump(ClfResults_bl, open(outfile + '_bl.pkl','wb')) \n","     \n","    ## Step 6:\n","    print 'Evaluation of results phase ..'\n","    MesoPred.Evaluation(ClfResults_ridge, ClfResults_rf, ClfResults_bl, params) \n","    \n","    # Step 7:\n","    unanimity_thr = 0.2\n","    verdict, params_to_fit = MesoPred.StabilityInvestigator(ClfResults_ridge['Model Storage'], unanimity_thr)\n","    if verdict == 'Full Fit': \n","        final_model = Ridge(**params_to_fit).fit(ridge_pred[5], ridge_pred[2])\n","    elif verdict == 'Partial Fit': \n","        final_model = [Ridge(**model.best_params_).fit(ridge_pred[5], ridge_pred[2])\\\n","                       for model in ClfResults_ridge['Model Storage']]\n","    \n","    ClfResults_ridge['final model'] = final_model\n","    final_model = []\n","    pk.dump(ClfResults_ridge, open(outfile + '_ridge.pkl','wb'))\n","    \n","    clear_output()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["In case that a set of results from a number of tracer categories have been stored,  \n","they can be loaded as shown bellow in order to save time.   \n","The data from the ridge regression model are being used   \n","due to the model's superior performance over the rest of  \n","the models as shown by the cross-validation evaluation method."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["ClfResults_ridge = {}; ridge_pred = {}\n","unanimity_thr = 0.2\n","for key in ConDict.keys():\n","    if os.path.isfile('./' + key + '_all_results' + '_ridge.pkl') == True:\n","        ClfResults_ridge[key] = {key:val for key,val in tmp2.items() if key != 'Model Storage'}\n","        ridge_pred[key] = [ClfResults_ridge[key]['y_actual'],\n","                           ClfResults_ridge[key]['y_pred'],\n","                           ClfResults_ridge[key]['Gene Expression']]\n","        set_trace()\n","        '''verdict, params_to_fit = MesoPred.StabilityInvestigator(tmp2['Model Storage'], unanimity_thr)\n","        if verdict == 'Full Fit': \n","            final_model = 1 #Ridge(**params_to_fit).fit(ridge_pred[key][2], ridge_pred[key][1])\n","        elif verdict == 'Partial Fit': \n","            final_model = 2 #[Ridge(**model.best_params_).fit(ridge_pred[key][2], ridge_pred[key][1])\\\n","                           #for model in tmp2['Model Storage']]'''\n","        tmp2 = []; final_model = []"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["One of the last demonstrations regarding the predictive pipeline is about binarized connectivity patterns. This could be useful in the case that a particular researcher is not interested in the connectivity strength between two brain areas but in the presence of connections between areas, whose strength exceeds a certain threshold. For that reason, the Convert2ROC function is being called for all predicted connectivity patterns.     \n","The idea is the utilize the Area under the ROC curve (AURoc) as an evaluation measure in order to estimate the most optimal binarizing threshold. The threshold for which the AURoc is being maximized is selected as the most optimal. \n","The steps that describe this procedure are being explained in the Convert2ROC function."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["#MesoPred = MesoconnectomePredictor(GeneExp, ConDict['wild_type']['ConMat'])\n","cutoff_col = {}\n","for driver_line in ridge_pred.keys():\n","    print 'driver line: ' + str(driver_line)\n","    cutoff_col[driver_line] = MesoPred.Convert2ROC(ridge_pred[driver_line][1],ridge_pred[driver_line][0])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Lets take the case where we want to binarize the connectivity patterns in experiments belonging to the cre-line tracers tested in our analysis such as Cre_GN220. We utilize the our results from the previous function as shown bellow "]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["experiments_len = np.shape(ridge_pred['Ntsr1-Cre_GN220'][0])[1]\n","BinarizedConnections = {}\n","for driver_line in ridge_pred.keys():\n","    BinarizedConnections[driver_line] = np.zeros(np.shape(ridge_pred['Ntsr1-Cre_GN220'][0]))\n","    for tracer_num in range(experiments_len):  \n","        BinarizedConnections[driver_line][:,tracer_num] = SL.BinarizeTheVector\\\n","                                                         (ridge_pred['Ntsr1-Cre_GN220'][0][:,tracer_num],\\\n","                                                            cutoff_col['Ntsr1-Cre_GN220'][tracer_num][0])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## VISUALIZATION CHAPTER  \n","### Authors: Nestor Timonidis, Paul Tiesinga\n","In this section, a number of steps are being followed   \n","for visualizing brain slices containing gene expression   \n","or connectivity information\n",""]},{"metadata":{},"cell_type":"markdown","source":["Utilization of the MouseConnectivityCache (mcc) tool, provided by the Allen Institute for Brain Science Software Development Toolkit (SDK) at:  \n","https://alleninstitute.github.io/AllenSDK/_modules/allensdk/core/mouse_connectivity_cache.html    \n","The cortical flatmap templates used in this analysis, were downloaded from the informatics-archive of the Allen Institute for Brain Science:   \n","http://download.alleninstitute.org/informatics-archive/current-release/mouse_ccf/cortical_coordinates/ccf_2016/  \n","The cortical_map_10.py script is a slightly modified version of the cortical_map.py script that was provided by the Allen Institute's github as part of the mouse_connectivity_models tool:   \n","https://github.com/AllenInstitute/mouse_connectivity_models  \n","The difference with the original script is that cortical_map_10 is modified to incorprorate cortical flatmap templates of 10 micrometer resolution.  \n","With the mcc tool, the annotation volume of the mouse brain is being downloaded in both 25 and 10 micrometer resolution for visualization purposes."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["mcc_25 = MouseConnectivityCache(resolution = 25)\n","mcc_10 = MouseConnectivityCache(resolution = 10)\n","Annotation_25, annot_info = mcc_25.get_annotation_volume()\n","Annotation_10, annot_info = mcc_10.get_annotation_volume()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Application of a set of experiment ids in the brain visualization tools (Brain Plotter)  "]},{"metadata":{},"cell_type":"markdown","source":["In order to make a cortical flatmap visualization for the mouse cortex,    \n","we need to initially ensure that we have reduced the complexity  \n","of structural brain areas to a layer inspecific level that corresponds    \n","to clear anatomically distinct areas like the primary visual or motor cortex.   \n","Therefore we utilize the MouseConnectivityCache tool to get the ontology    \n","tree of brain areas, then we reduce it by the isocortex and for each    \n","isocortical area, we take the identity of its father node, or an area  \n","belonging up in the tree hierarchy.      \n","Having achieved that, the next step is to replace the identity of each    \n","area in the annotation volume structure by the father identity.  "]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["# grab the StructureTree instance\n","structure_tree = mcc_10.get_structure_tree()\n","oapi           = OntologiesApi()\n","# Get isocortex summary structures\n","kid_to_father = {}\n","summary_structures = structure_tree.get_structures_by_set_id([688152357])\n","for val in summary_structures:\n","    kids = structure_tree.descendant_ids([val['id']])\n","    for kid in kids[0]:\n","        kid_to_father[kid] = val['id']\n","\n","# For each distinct isocortical area, replace its children annotation with the area's id\n","father_acros_indices = {val['acronym']:val['id'] for val in summary_structures}\n","\n","#store the original annotation shape because it will be flatten for computational simplicity when updating the parent nodes\n","orig_annot_shape = np.shape(Annotation_10)\n","flat_annot = np.ndarray.flatten(Annotation_10, order = 'C')\n","\n","# Create a copy of the annotation structure that reduces areas to their parent nodes\n","Annotation_copy = np.zeros(np.shape(flat_annot))\n","\n","for kid_id,parent_id in kid_to_father.items():\n","    tmp  = flat_annot == int(kid_id)\n","    nzero_ids = np.nonzero(tmp)\n","    Annotation_copy[nzero_ids] = parent_id \n","     \n","with h5py.File('Annotation_copy.hdf5','w') as f2:\n","     f2.create_dataset('dataset1', data = Annotation_copy)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Selection of the 11th and 21st experiment for demonstration of the BrainPlotter tool.   \n","Data structures for storing the mapping of unionized projections to volumetric scale,  \n","for the actual and predicted patterns, are being initialized.  \n","Moreover, the dictionary that maps the identities of structures to their positions  \n","in the original raw unionized dataset is being updated to include only the   \n","structures that were used in the predictive pipeline.  "]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["tracer_for_selection = 'Ntsr1-Cre_GN220'\n","experiment_to_vis = [10,20]\n","UnionToVoxel_pred_25 = {}; UnionToVoxel_pred_10 = {}; UnionToVoxel_25 = {}; UnionToVoxel_10 = {}\n","struct_idx_dict_cp = struct_idx_dict.copy()\n","for key,value in struct_idx_dict.items():\n","    if value not in params['remaining_indices']:\n","       del struct_idx_dict_cp[key]\n","struct_idx_dict = struct_idx_dict_cp    \n","#Annotation_copy = np.asarray(h5py.File('Annotation_copy.hdf5','r')['dataset1'], dtype = np.int32)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["For each one of the selected experiments:  \n","0.   Initializing the data for usage during the visualization process.\n","1.   Mapping of unionized projections to volumetric space for actual and predicted projection patterns,   using the FromUnion2Voxel function.\n","2.   Repetition of step 1 for 10 micrometers instead of 25, since the cortical flatmap visualization requires 10 micrometer resolution, while the brain slice visualization requires 25 micrometers.\n","3.   Initialization of the BrainPlotter class instances,\n","4.   Call of the plot_slice function to visualizing projections of the currently selected experiment in the superior-inferior and left-right coordinates using a brain slice.\n","5.   Call of the plot_flatmap function to visualizing projections of the currently selected experiment on the mouse cortex, using a cortical flatmap."]},{"metadata":{"trusted":true},"cell_type":"code","source":["for j,experiment in enumerate(experiment_to_vis):\n","    \n","    # Step 0\n","    key_to_save = tracer_for_selection + '_' + str(j)\n","    exp_id = ConDict[tracer_for_selection]['id'][j]\n","    ConStr = ConDict[tracer_for_selection]['ConMat']\n","    Pred_ConStr = ridge_pred[tracer_for_selection]\n","    \n","    # Step 1\n","    UnionToVoxel_25[key_to_save], UnionToVoxel_pred_25[key_to_save] = SL.FromUnion2Voxel(\n","         Annotation_25, struct_idx_dict, Pred_ConStr[1][:,j], params, \n","         Pred_ConStr[0][:,j])\n","    with h5py.File('./UnionToVoxel_25_for_' + str(key_to_save) + '.hdf5','w') as fp:\n","        fp.create_dataset('dataset1', data = UnionToVoxel_25[key_to_save], \n","                          dtype = np.float32) \n","    with h5py.File('./UnionToVoxel_25_pred_for_' + str(key_to_save) + '.hdf5','w') as fp:\n","        fp.create_dataset('dataset1', data = UnionToVoxel_pred_25[key_to_save], dtype = np.float32)  \n","    \n","    # Step 2   : Due to limitations on available memory, we shall skip the volumetric mapping on the 10 micrometer \n","    #            resolution. We shall instead show in the next cell the 10 micrometer cortical flatmap on the \n","    #            actual raw volumetric data\n","    \n","    # UnionToVoxel_10[key_to_save], UnionToVoxel_pred_10[key_to_save] = \\\n","    #                  FromUnion2Voxel(Annotation_10, struct_idx_dict,\\ \n","                                       #Pred_ConStr[1][:,j], Pred_ConStr[0][:,j])    \n","        \n","    # Step 3   \n","    #BP_10 = BrainPlotter(mcc_10, experiment_id = exp_id, res = 10, \n","                          #driver = tracer_for_selection + str(exp_id))\n","    BP_25 = SL.BrainPlotter(mcc_25, experiment_id = exp_id, \n","                            res = 25, driver = tracer_for_selection + str(exp_id))\n","    \n","    # Step 4\n","    BP_25.plot_slice(struct_idx_dict, 'None', Annotation_25, \n","                     matrix = UnionToVoxel_25[key_to_save],\\\n","                     savefile = 'slice visualization for : ' + \n","                     str(tracer_for_selection) + ' ' +  str(j+1) + '.png')\n","    BP_25.plot_slice(struct_idx_dict, 'None', Annotation_25, \n","                     matrix = UnionToVoxel_pred_25[key_to_save],\\\n","                     savefile = 'slice visualization for : ' + \n","                     str(tracer_for_selection) + ' ' +  str(j+1) + ' (predicted).png')\n","\n","    # Step 5:  Skipping the step (see Step 2 comments)\n","    # BP_10.plot_flatmap('None', Annotation_copy, matrix = UnionToVoxel_10[key_to_save],\\\n","    #                   savefile = 'flatmap visualization for : ' \n","                        #+ str(tracer_for_selection) + ' ' +  str(j+1) + '.jpg')\n","    # BP_10.plot_flatmap('None', Annotation_copy, matrix = UnionToVoxel_pred_10[key_to_save],\\\n","     #                  savefile = 'flatmap visualization for : ' + str(tracer_for_selection) \n","                        #+ ' ' +  str(j+1) + '.jpg') "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We are also interested in producing the aforementioned figures with the actual raw volumetric data. Therefore, steps 3-5 are repeated without giving any volumetric matrix as input to the plot_slice and plot_flatmap functions. In that case, the identities of the original experiments are used to download and visualize the actual raw data."]},{"metadata":{"trusted":true},"cell_type":"code","source":["for j,experiment in enumerate(experiment_to_vis):\n","    \n","    # Step 0\n","    exp_id = ConDict[tracer_for_selection]['id'][j]\n","\n","    # Step 3          \n","    BP_10 = SL.BrainPlotter(mcc_10, experiment_id = exp_id, res = 10, \n","                            driver = tracer_for_selection + str(exp_id))\n","    BP_25 = SL.BrainPlotter(mcc_25, experiment_id = exp_id, res = 25, \n","                            driver = tracer_for_selection + str(exp_id))\n","    \n","    # Step 4\n","    BP_25.plot_slice(struct_idx_dict, 'None', Annotation_25, matrix = 'None',\\\n","                     savefile = 'slice visualization for : ' + \n","                     str(tracer_for_selection) + ' ' +  str(j+1) + '.png')\n","    # Step 5\n","    BP_10.plot_flatmap('None', Annotation_10, matrix = 'None',\\\n","                       savefile = 'flatmap visualization for : ' + \n","                       str(tracer_for_selection) + ' ' +  str(j+1) + '.jpg')\n","    "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Link to Scalable Brain Atlas Composer Section\n","### Authors: Rembrandt Bakker, Nestor Timonidis"]},{"metadata":{},"cell_type":"markdown","source":["In this part, the Scalable Brain Atlas (SBA) Composer visualization tool is being used to visualize actual and predicted data that have been used and processed throughout the analysis.      \n","The website of the SBA Composer can be accessed by this link:  \n","https://scalablebrainatlas.incf.org/composer/?template=ABA_v3  \n","A series of steps bellow describe the visualization process."]},{"metadata":{},"cell_type":"markdown","source":["In order for results to be visualized, a conversion to json format is necessary.\n","Therefore the dictionary bellow indicates the format that results must have in order to be visualized.\n","Specifically:  \n","*    provider    = the name of the tool to be used. sba stands for scalable brain atlas.\n","*    atlas       = the Common Coordinate Framework (CCF) version that was used by the Allen Institute to process the raw data that the user has used throughout the analysis. In this case ABA_v3 stands for Allen Brain Atlas version 3, since our data were processed according to that framework.  \n","*    orientation = the orientation used in 3D space for the input. RAS stands for: right-anterior-superior.\n","*    unit        = the scaling unit. mm stands for milimiters.\n",""]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["JSonDict = {'bas': {'provider': \"sba\",\n","             'atlas': \"ABA_v3\",\n","             'orientation': \"RAS\",\n","             'unit': \"mm\"},\n","             'style': {}, 'markers':[]} "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["According to the aforementioned format, we select predictions of all tracing data tested by our predictive model.  \n","For non wild-type, meaning cre-line experiments, we also incorporate information regarding the layer and cell types  \n","most commonly expressed in the injected source brain areas.  \n","Furthermore, we select to visualize the r2 measure for evaluation of predictive performance.   \n","For each individual experiment we embed the r2 measure in the spatial locations of the structural  \n","brain area corresponding to the injected source location."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["for tracer_name in ridge_pred.keys():\n","    if tracer_name == 'wild_type':\n","       tracer_layer = ''\n","       tracer_cell  = ''\n","    else:\n","       tracer_layer = ConDict[tracer_name]['layer'][0]\n","       tracer_cell =  ConDict[tracer_name]['cell-type'][0]\n","    for idx, measure in enumerate(ClfResults_ridge[tracer_name]['r2']):\n","        JSonDict['markers'].append({})\n","        JSonDict['markers'][len(JSonDict['markers'])-1]['value']    = str(measure[0])\n","        JSonDict['markers'][len(JSonDict['markers'])-1]['position'] = [str(coo) for coo in ConDict[tracer_name]['Coordinates'][idx]]\n","        JSonDict['markers'][len(JSonDict['markers'])-1]['region']   = ConDict[tracer_name]['structure-abbrev'][idx]\n","        JSonDict['markers'][len(JSonDict['markers'])-1]['relsize']  = \"0.5\"\n","        JSonDict['markers'][len(JSonDict['markers'])-1]['cre-line'] = tracer_name\n","        if 'layer' in ConDict[tracer_name]:\n","            JSonDict['markers'][len(JSonDict['markers'])-1]['layer']  = ConDict[tracer_name]['layer'][idx] \n"," "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["In this step, a sbaInterface_class object is being initialized to be used in the visualization process.    \n","The sbaInterface_class acts as the interface between our data and the tool.  \n","As an initial test, a window with the SBA composer opens without data.  "]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["from IPython.display import display, Javascript, clear_output\n","\n","# SBA Composer page to load: here it is the -dev version and atlas ABA_v3\n","sbaHost = 'https://scalablebrainatlas.incf.org/composer-dev';\n","sbaUrl = sbaHost+'/?template=ABA_v3';\n","\n","class sbaInterface_class:\n","    def __init__(this,sbaUrl):\n","        # In Javascript, load sbaInterface.js and create a new sbaInterface object\n","        display(Javascript(\"\"\"\n","            var script = document.createElement('script');\n","            script.src = '{}/../js/sba-interface.js';\n","            script.onload = function() {{\n","              window.global_sbaInterface = new sbaInterface_class('{}');\n","            }}\n","            document.head.appendChild(script)\n","        \"\"\".format(sbaHost,sbaUrl)))\n","        clear_output()\n","        \n","    def send(this,sbaCommand):\n","        display(Javascript(\"\"\"window.global_sbaInterface.send({})\"\"\".format(json_encode(sbaCommand))))\n","        clear_output() # prevents clogging the Jupyter notebook\n","\n","sbaInterface = sbaInterface_class(sbaUrl)\n",""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["In this step, the predictive results in json format  \n","are being given as input to the send function of the    \n","sbaInterface object. The result is visualization of   \n","our selected measure across the mouse brain.  "]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["#sbaInterface.send(json.dumps({'method':'Composer.scatter3d' ,'params' : JSonDict}))\n","sbaCommand = {\n","    \"method\":\"Composer.scatter3d\",\n","    'params' : JSonDict\n","}\n","sbaInterface.send(sbaCommand)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["After the prediction of connectivity patterns with the training of unionized data has been evaluated   \n","and visualized,the next and final step is the visual inspection of the connectivity patterns in the   \n","volumetric space of 25 or 10 micrometers. In this example, the UnionToVoxel_10 is being used,   \n","that in previous steps stored a mapping of the actual and predicted connectivity patterns   \n","in the volumetric space. For each individual experiment whose actual and predicted patterns   \n","have been stored by UnionToVoxel_10, the data structure is being converted into nifti format  \n","and given as input to the send function in order to be visualized.  \n","Following that command, a new window will pop-up and the user can  visually inspect the patterns  \n","by zooming in/out and rotating the mouse brain."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["nifti_urls = SL.Save2Nifti(UnionToVoxel_25, affine_scale = 0.025)\n","exp_to_select = nifti_urls.keys()[0]\n","with open(nifti_urls[nifti_urls.keys()[0]], \"rb\") as fp:\n","  sbaCommand = {\n","    \"method\":\"Composer.import\",\n","    \"params\": {\n","      \"name\": nifti_urls[nifti_urls.keys()[0]].split('.')[0] + '.bas{sba.ABA_v3^corner,PIR,mm}.nii.gz', \n","      \"encoding\": 'base64',\n","      \"contents\": base64.b64encode(fp.read()).decode('utf-8')\n","    }\n","  }\n","\n","# send the command to sbaComposer\n","sbaInterface.send(sbaCommand)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["**As a side note**: The plane corresponding to the brain slice at the SBA composer is not fixed but can be rotated with the use of the left click or zoomed with the right click. Moreover, the toolbar at the left of the screen provides to the user a set of visualization configurations.\n","Furthermore in terms of predictive results, the black color at the SBA composer represents a lack of connection between the voxels and the corresponding target area, while the white color represents connection between them."]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"markdown","source":["Clearing storage space from the nifti volumes"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["!ls"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["!rm *.nii.gz"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python2","display_name":"Python 2","language":"python"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython2","version":"2.7.15","file_extension":".py","codemirror_mode":{"version":2,"name":"ipython"}}},"nbformat":4,"nbformat_minor":1}