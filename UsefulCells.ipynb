{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import call\n",
    "import pickle as pk\n",
    "from IPython.display import clear_output\n",
    "current_dir = os.listdir('./')\n",
    "for path in os.listdir('../25 3 2019/'):\n",
    "    if os.path.islink(path) is not True and path not in current_dir:\n",
    "        call(['ln','-s','../25 3 2019/'+ path, path])        \n",
    "from cfg import *\n",
    "os.chdir('../CCP_Collab_Backup_2/')\n",
    "import PrimaryLibrary as PL\n",
    "imp.reload(PL)\n",
    "import MorphologyLibrary as MLab\n",
    "imp.reload(MLab)\n",
    "import Allen_API_Library as API\n",
    "imp.reload(API)\n",
    "MesoPred = PL.MesoconnectomePredictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the MesoPred params with information regarding subcortical and thalamic indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.api.queries.ontologies_api import OntologiesApi\n",
    "\n",
    "oapi = OntologiesApi()\n",
    "mcc = MouseConnectivityCache()\n",
    "structure_tree = mcc.get_structure_tree()\n",
    "\n",
    "# get the ids of all the structure sets in the tree\n",
    "structure_set_ids = structure_tree.get_structure_sets()\n",
    "\n",
    "# query the API for information on those structure sets\n",
    "pd.DataFrame(oapi.get_structure_sets(structure_set_ids))\n",
    "\n",
    "summary_structures = structure_tree.get_structures_by_set_id([687527670])\n",
    "subcortical_structures = []\n",
    "thalamic_structures    = []\n",
    "cortical_structures    = []\n",
    "for val in summary_structures:\n",
    "    if val['acronym'] == 'TH':\n",
    "        kids = structure_tree.descendant_ids([val['id']])\n",
    "        thalamic_structures.extend(kids[0])\n",
    "    if val['acronym'] == 'Isocortex': \n",
    "        ids = structure_tree.descendant_ids([val['id']])\n",
    "        cortical_structures.extend(kids[0])\n",
    "    else:\n",
    "        kids = structure_tree.descendant_ids([val['id']])\n",
    "        subcortical_structures.extend(kids[0])\n",
    "     \n",
    "with open('structures.csv','rb') as fp:\n",
    "    structure       = PL.readtable(fp) \n",
    "    struct_idx_dict = {val:idx for idx,val in enumerate(structure['id'])}\n",
    "for idx,val in enumerate(thalamic_structures):\n",
    "    thalamic_structures[idx] = struct_idx_dict[str(val)]\n",
    "for idx,val in enumerate(subcortical_structures):    \n",
    "    subcortical_structures[idx] = struct_idx_dict[str(val)] \n",
    "for idx,val in enumerate(cortical_structures):    \n",
    "    cortical_structures[idx] = struct_idx_dict[str(val)] \n",
    "    \n",
    "MesoPred.targetprofiles['cortical structures'] = cortical_structures   \n",
    "cre_dict_2 = OrderedDict([(key,value['layer'][0] + ' ' + value['cell-type'][0])  for key,value in MesoPred.ConDict.items() if 'layer' in value.keys()])\n",
    "cre_dict_2 = pd.DataFrame(cre_dict_2, index = ['cre-profiles']).T\n",
    "cre_dict_2.to_csv('paper1_figures/cre_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeneExp        = h5py.File('G_Exp.hdf5', 'r')['dataset1']\n",
    "a,b,c,d  = MesoPred.PreProcessing(GeneExp[MesoPred.params['leaf_keys'],:], \n",
    "                                  MesoPred.params,\n",
    "                                  MesoPred.ConDict['wild_type']['ConMat'][MesoPred.params['leaf_keys'],:])\n",
    "ClfResults_ridge = {}; ridge_pred = {}\n",
    "MesoPred.params           = pk.load(open('updated_params.pkl','rb'))\n",
    "for key in MesoPred.ConDict.keys():\n",
    "    if os.path.isfile(MesoPred.params['prefix'] + key + '_all_results' + '_ridge.pkl') == True:\n",
    "        infile = MesoPred.params['prefix'] + key + '_all_results' + '_ridge.pkl'\n",
    "        print infile\n",
    "        tmp = pk.load(open(infile,'r'))\n",
    "        ClfResults_ridge[key] = {key:val for key,val in tmp.items()}\n",
    "         \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure  = 'AURoc'\n",
    "MetaInfo = {}\n",
    "for key in ClfResults_ridge.keys():\n",
    "    tmp1 = [val[0] for val in ClfResults_ridge[key][measure]] \n",
    "    sort1 = np.argsort(tmp1)[::-1]; sort3 = np.sort(tmp1)[::-1]\n",
    "    set_length = len(sort1)   \n",
    "\n",
    "    MetaInfo['min1']  = [MesoPred.ConDict[key]['structure-abbrev'][sort1[set_length-1]], sort3[set_length-1]]\n",
    "    MetaInfo['max1']  = [MesoPred.ConDict[key]['structure-abbrev'][sort1[0]], sort3[0]]\n",
    "    MetaInfo['med1']  = [MesoPred.ConDict[key]['structure-abbrev'][sort1[set_length/2]], sort3[set_length/2]]\n",
    "\n",
    "    MetaInfo['save_file']  = key + '_' + measure +'.jpg'\n",
    "    MetaInfo['save_file2'] = key + '_' + measure +'.eps'\n",
    "    MetaInfo['title']      = key  \n",
    "    MetaInfo['ylabel']     = measure\n",
    "    MetaInfo['xlabel']     = 'Ridge'\n",
    "    MetaInfo['lb']         = np.min(ClfResults_ridge[key][measure]) - 0.1\n",
    "    MetaInfo['ub']         = 1.0\n",
    "   \n",
    "    print key, np.median(ClfResults_ridge[key][measure]), sci.stats.iqr(ClfResults_ridge[key][measure])\n",
    "    fsz = 14\n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.tight_layout()\n",
    "    plt.rcParams['figure.figsize']\n",
    "    box = plt.boxplot(ClfResults_ridge[key][measure], 0, 'gD', widths = 0.6, whis = [5,95])\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_tick_params(labelsize = 16)\n",
    "    ax.yaxis.set_tick_params(labelsize = 16)\n",
    "    plt.text(0.55, MetaInfo['max1'][1], MetaInfo['max1'][0], fontsize = fsz)\n",
    "    plt.text(0.55, MetaInfo['min1'][1], MetaInfo['min1'][0], fontsize = fsz)\n",
    "    plt.text(0.55, MetaInfo['med1'][1], MetaInfo['med1'][0], fontsize = fsz)\n",
    "    plt.title(MetaInfo['title'], fontsize = 20)\n",
    "    plt.xlabel(MetaInfo['xlabel'], fontsize = 18)\n",
    "    plt.ylabel(MetaInfo['ylabel'], fontsize = 18)\n",
    "    \n",
    "    for key2 in box.keys():\n",
    "        for bp in box[key2]:\n",
    "            bp.set(linewidth = 2)\n",
    "            \n",
    "    if key == 'wild_type':\n",
    "        lb = 0.7\n",
    "    else:\n",
    "        lb = 0.8\n",
    "    plt.yticks(np.arange(0.7,1.01,0.05))\n",
    "    #plt.yticks(np.arange(0.4,1.0,0.05))\n",
    "\n",
    "    plt.savefig('paper1_figures/regression_accuracy_figures/' + MetaInfo['save_file'])\n",
    "    plt.savefig('paper1_figures/regression_accuracy_figures/' + MetaInfo['save_file2'])\n",
    "    plt.show(block = False)\n",
    "    plt.pause(1)\n",
    "    plt.close()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_summary, proj_pred_summary, laminar_profs = MesoPred.PlotStatistics(ClfResults_ridge)\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Components = pk.load(open('saves/Components.pkl','rb'))\n",
    "Code = pk.load(open('saves/Code.pkl','rb'))\n",
    "dlsc_mdl = pk.load(open('saves/dict_mdl.pkl','rb'))\n",
    "G_Components = pk.load(open('saves/Grange_Atoms.pkl','rb'))\n",
    "G_Code = pk.load(open('saves/Grange_Code.pkl','rb'))\n",
    "G_dlsc_mdl = pk.load(open('saves/Grange_mdl.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Experiment: !!!!\n",
    "I will remake the regionalized array by mixing projection patterns from different profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = pk.load(open('model_meta.pkl','rb'))\n",
    "layer_resolved_array = pk.load(open('layer_resolved_array.pkl','rb'))\n",
    "print model_meta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LayerArray,ModelMeta = MesoPred.GetLayerResolvedArray(mode = 'unionized', \n",
    "                                                      cre_file = 'Supplementary Table 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spears = sci.stats.spearmanr(new_layer_mat)\n",
    "source2source = spears[0]\n",
    "print source2source.shape\n",
    "\n",
    "new_laminar_order = []; neo_layers = []; restr_source = []\n",
    "for layer in np.unique(layers):\n",
    "    print ' layer {}'.format(layer)\n",
    "    commons = [idx for idx,val in enumerate(layers) if val == layer]\n",
    "    new_laminar_order.extend(commons)\n",
    "    neo_layers.extend([layers[idx] for idx in commons])\n",
    "    restr_source.extend([ModelMeta['source id'][idx] for idx in commons])\n",
    "    foreigners = [idx for idx,val in enumerate(layers) if val != layer]\n",
    "    \n",
    "new_laminar_order = np.asarray(new_laminar_order)\n",
    "source2source2 = source2source[new_laminar_order,:]\n",
    "source2source2 = source2source2[:,new_laminar_order]\n",
    "\n",
    "\n",
    "#source_df = pd.DataFrame(data = source2source2,\n",
    "#                           index = neo_layers, \n",
    "#                           columns = neo_layers) \n",
    "source_df = pd.DataFrame(data = source2source2,\n",
    "                           index = restr_source, \n",
    "                           columns = restr_source) \n",
    "\n",
    "sil_score = metrics.silhouette_score(source2source2, neo_layers, metric = 'euclidean', random_state = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spears = sci.stats.spearmanr(new_layer_mat)\n",
    "source2source = spears[0]\n",
    "print source2source.shape\n",
    "\n",
    "new_laminar_order = []; neo_layers = []\n",
    "for layer in np.unique(layers):\n",
    "    print ' layer {}'.format(layer)\n",
    "    commons = [idx for idx,val in enumerate(layers) if val == layer]\n",
    "    new_laminar_order.extend(commons)\n",
    "    neo_layers.extend([layers[idx] for idx in commons])\n",
    "    foreigners = [idx for idx,val in enumerate(layers) if val != layer]\n",
    "    \n",
    "new_laminar_order = np.asarray(new_laminar_order)\n",
    "neo_layers        = np.asarray(neo_layers)\n",
    "source2source2    = source2source[new_laminar_order,:]\n",
    "source2source2    = source2source2[:,new_laminar_order]\n",
    "\n",
    "\n",
    "source_df = pd.DataFrame(data = source2source2,\n",
    "                           index = neo_layers, \n",
    "                           columns = neo_layers) \n",
    "\n",
    "sil_score = metrics.silhouette_score(source2source2, neo_layers, metric = 'euclidean', random_state = 3)\n",
    "#sil_score = metrics.silhouette_score(new_layer_mat.T, layers, metric = 'euclidean', random_state = 3)\n",
    "print sil_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_num       = 1000\n",
    "prm_score_list = []\n",
    "for num in range(perm_num):\n",
    "    prm_ids               = np.random.permutation([idx for idx in range(len(source2source2))])\n",
    "    new_layer_mat_prm     = new_layer_mat[:,prm_ids]\n",
    "    new_laminar_order_prm = new_laminar_order[prm_ids]\n",
    "    #neo_layers_prm        = neo_layers[prm_ids]\n",
    "    \n",
    "    source2source_prm     = sci.stats.spearmanr(new_layer_mat_prm)[0]\n",
    "    source2source2_prm    = source2source_prm[new_laminar_order,:]\n",
    "    source2source2_prm    = source2source2_prm[:,new_laminar_order]\n",
    "    \n",
    "    source_df = pd.DataFrame(data = source2source2_prm,\n",
    "                            index = neo_layers, \n",
    "                            columns = neo_layers) \n",
    "    \n",
    "    sil_score_prm = metrics.silhouette_score(source2source2_prm, neo_layers, metric = 'euclidean', random_state = 3)\n",
    "    #sil_score_prm = metrics.silhouette_score(new_layer_mat_prm.T, layers[prm_ids], metric = 'euclidean', random_state = 3) \n",
    "    prm_score_list.append(sil_score_prm)\n",
    "    \n",
    "    \n",
    "# pvallssss\n",
    "laminar_pval = len([val for val in prm_score_list if val >= sil_score])/(1.0*perm_num)\n",
    "print laminar_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = h5py.File('for_TVMB/Merge_TVMB_pred_Connectivity.h5','r')\n",
    "prim_strs =  fp['region_labels'][()]\n",
    "fp.close()\n",
    "struct_dict = OrderedDict([(val[val.index(' ') + 1:],structure['acronym'][idx]) for val in prim_strs for idx in range(len(structure['acronym'])) if val[val.index(' ') + 1:] == structure['name'][idx]])\n",
    "struct_dict = pd.DataFrame(struct_dict, index = ['brain regions acronyms']).T\n",
    "struct_dict.to_csv('paper1_figures/primary_structures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 18)\n",
    "ax.yaxis.set_tick_params(labelsize = 18)\n",
    "sns.heatmap(source_df)\n",
    "plt.xticks(rotation = 360-90)\n",
    "plt.savefig('paper1_figures/laminar_heatmap.eps')\n",
    "cax = plt.gcf().axes[-1]\n",
    "cax.tick_params(labelsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(new_layer_mat, open('paper1_figures/new_layer_mat.pkl','wb'))\n",
    "pk.dump(ModelMeta, open('paper1_figures/ModelMeta.pkl','wb'))\n",
    "new_layer_mat = pk.load(open('paper1_figures/new_layer_mat.pkl','rb'))\n",
    "ModelMeta = pk.load(open('paper1_figures/ModelMeta.pkl','rb'))\n",
    "print model_meta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LayerArray2 = []\n",
    "for modelaki in ModelMeta['model']:\n",
    "    LayerArray2.append(modelaki.connection_density.T)\n",
    "     \n",
    "LayerArray2 = np.dstack(LayerArray2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_layer_mat = np.zeros((np.shape(LayerArray2)[0],np.shape(LayerArray2)[1]))\n",
    "with open('structures.csv','rb') as fp:\n",
    "                structure       = PL.readtable(fp) \n",
    "                struct_idx_dict = {val:idx for idx,val in enumerate(structure['id'])}\n",
    "    \n",
    "layers = PL.LaminarRegistration(ModelMeta['source id'])\n",
    "for idx,source in enumerate(layers):\n",
    "    prof_hit = [prof_id for prof_id,val in enumerate(ModelMeta['layer profiles'])                 \n",
    "                if val.split(' ')[0].replace('L','layer').split('layer')[1] \n",
    "                in source.split('layer ')[1] and val != 'layer inspecific']\n",
    "         \n",
    "    if len(prof_hit) == 0:\n",
    "        new_layer_mat[:,idx] = LayerArray2[:,idx,5]\n",
    "    else:\n",
    "        new_layer_mat[:,idx] = LayerArray2[:,idx,prof_hit[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target  = np.asarray(ModelMeta['target id'])\n",
    "source  = np.asarray(ModelMeta['source id'])\n",
    "resorting_trg_indices = np.argsort(ModelMeta['target id'])\n",
    "#resorting_trg_indices = np.argsort(layers)\n",
    "model_meta['sorting target id'] = target[resorting_trg_indices]\n",
    "resorting_src_indices = np.argsort(ModelMeta['source id'])\n",
    "model_meta['sorting source id'] = source[resorting_src_indices]\n",
    "layer_array_2 = new_layer_mat[resorting_trg_indices,:]\n",
    "layer_array_3 = layer_array_2[:,resorting_src_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LayerDf = pd.DataFrame(data = layer_array_3,\n",
    "                          index = model_meta['sorting target id'], \n",
    "                           columns = model_meta['sorting source id'])\n",
    "pk.dump(LayerDf, open('paper1_figures/Layer_specific_Df.pkl','wb'))\n",
    "\n",
    "#LayerDf = pk.load(open('paper1_figures/Layer_specific_Df.pkl','rb'))\n",
    "plt.figure(figsize = (30,15))\n",
    "plt.title('laminar specific regionalized array', fontsize = 32)\n",
    "sns.set(font_scale=2.1)\n",
    "sns.heatmap(LayerDf)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 22)\n",
    "ax.yaxis.set_tick_params(labelsize = 22)\n",
    "plt.xticks(rotation = 290)\n",
    "plt.yticks(rotation = 30)\n",
    "plt.savefig('paper1_figures/Merged_RegionalizedArray.jpg')\n",
    "plt.savefig('paper1_figures/Merged_RegionalizedArray.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sortedHierarchy.json','r') as fp:\n",
    "     hierarchy_in_structs = json.load(fp)\n",
    "        \n",
    "        \n",
    "targets = np.asarray([MesoPred.targetprofiles['str_acronym'][struct_idx_dict[str(val)]] for val in model_meta['target id']])\n",
    "sources = np.asarray([MesoPred.targetprofiles['str_acronym'][struct_idx_dict[str(val)]] for val in model_meta['source id']])\n",
    "resorting_trg_indices = np.argsort(targets)\n",
    "model_meta['sorting target id'] = targets[resorting_trg_indices]\n",
    "resorting_src_indices = np.argsort(sources)\n",
    "model_meta['sorting source id'] = sources[resorting_src_indices]\n",
    "\n",
    "layer_array_2 = layer_resolved_array[:,resorting_trg_indices,:]\n",
    "layer_array_3 = layer_array_2[:,:,resorting_src_indices]\n",
    "\n",
    "for idx,profile in enumerate(model_meta['layer profiles']):\n",
    "     \n",
    "        \n",
    "    LayerDf = pd.DataFrame(data = layer_array_3[idx,0:25,0:25],\n",
    "                           index = model_meta['sorting target id'][0:25], \n",
    "                           columns = model_meta['sorting source id'][0:25])\n",
    "    plt.figure(figsize = (30,15))\n",
    "    sns.heatmap(LayerDf)\n",
    "    sns.set(font_scale = 2.3)\n",
    "    plt.title(profile, fontsize = 36)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_tick_params(labelsize = 26)\n",
    "    ax.yaxis.set_tick_params(labelsize = 26)\n",
    "    plt.xticks(rotation = 290)\n",
    "    plt.yticks(rotation = 30)\n",
    "    plt.savefig('paper1_figures/RegionalizedArray_{}.jpg'.format(profile.replace('/','')))\n",
    "    plt.savefig('paper1_figures/RegionalizedArray_{}.eps'.format(profile.replace('/','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I try a kernel regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myKernel(X_1,X_2):\n",
    "    return np.dot(np.dot(X_1[:,0:len(X_1[0])/2],X_2[:,0:len(X_2[0])/2].T), np.dot(X_1[:,len(X_1[0])/2:len(X_1[0])],X_2[:,len(X_2[0])/2:len(X_2[0])].T).T)\n",
    "    #return np.dot(x1)\n",
    "    \n",
    "#def myKernel(X_1,X_2):\n",
    "#    return np.dot(np.dot(X_1[:,0:len(X_1[0])/2],X_2[:,0:len(X_2[0])/2].T), np.dot(X_1[:,len(X_1[0])/2:len(X_1[0])],X_2[:,len(X_2[0])/2:len(X_2[0])].T).T)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics.pairwise import pairwise_kernels,linear_kernel\n",
    "KernelGeneMat = np.zeros((np.shape(G_red_proc)[0]**2,np.shape(G_red_proc)[1]*2))\n",
    "Y_vectorized = np.reshape(Y_red_proc,(np.shape(Y_red_proc)[0]*np.shape(Y_red_proc)[1],1))\n",
    "Y_vectorized = np.ravel(Y_vectorized)\n",
    "outer_cv = KFold(n_splits = 6, shuffle = True, random_state = 123)\n",
    "cnt = 0\n",
    "for target in range(len(G_red_proc)):\n",
    "    for source in range(len(G_red_proc)):\n",
    "        KernelGeneMat[cnt,:] = np.concatenate((G_red_proc[target,:],G_red_proc[source,:]), axis = 0)\n",
    "        cnt+=1\n",
    "\n",
    "svr = SVR(kernel=myKernel) \n",
    "svr_pred = cross_val_predict(svr, X = KernelGeneMat, y = Y_vectorized, cv = outer_cv)\n",
    "print 'svr model has been fitted'\n",
    "\n",
    "KernelMat = np.kron(G_red_proc,G_red_proc)\n",
    "\n",
    "#SVR(kernel=myKernel).fit(KernelMat,Y_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I do performance comparison between cre-line and wild-type data (boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_scores_prm = np.asarray([tracer for key in ridge_pred_prm.keys()\\\n",
    "#                                       for tracer in ridge_pred_prm[key]])  \n",
    "\n",
    "plt.figure(figsize = (16,6))\n",
    "box1 = plt.boxplot([module_based_pred['Cux2-IRES-Cre']['r2'],module_based_pred['Emx1-IRES-Cre']['r2'],module_based_pred['wild_type']['r2']], 0, 'gD', widths = 0.6, whis = [5,95])\n",
    "box2 = plt.boxplot([ridge_pred_prm['Cux2-IRES-Cre'],ridge_pred_prm['Emx1-IRES-Cre'],ridge_pred_prm['wild_type']], 0, 'r', widths = 0.6, whis = [5,95])\n",
    "#box1 = plt.boxplot([ridge_pred[key] for key in ridge_pred.keys()], 0, 'gD')\n",
    "#box2 = plt.boxplot([ridge_pred_prm[key] for key in ridge_pred.keys()], 0, 'r')   \n",
    "for key in box1.keys():\n",
    "        for bp1,bp2 in zip(box1[key],box2[key]):\n",
    "            bp1.set(linewidth = 2)\n",
    "            bp2.set(linewidth = 2)\n",
    "plt.xticks([1,2,3],['Cux2-IRES-Cre','Emx1-IRES-Cre','wild_type'])\n",
    "#plt.xticks([idx+1 for idx in range(len(ridge_pred.keys()))],[key for key in ridge_pred.keys()], rotation = 300)\n",
    "plt.yticks(np.arange(0.0,1.1,0.1))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 16)\n",
    "ax.yaxis.set_tick_params(labelsize = 20)\n",
    "plt.ylabel(r'$r^2$', fontsize = 20)\n",
    "#plt.savefig('paper1_figures/for_paul_20_6_19/permutation_for_modules.tiff')\n",
    "#plt.savefig('paper1_figures/for_paul_20_6_19/permutation_for_modules.eps')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "box1 = plt.boxplot([module_based_pred['Cux2-IRES-Cre']['r2'],module_based_pred['Emx1-IRES-Cre']['r2'],module_based_pred['wild_type']['r2']], 0, 'gD', widths = 0.6, whis = [5,95])\n",
    "for key in box1.keys():\n",
    "        for bp1 in box1[key]:\n",
    "            bp1.set(linewidth = 2)\n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics regrading gene modules and projection patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MesoPred.PlotStatistics(ClfResults_ridge, structure_summary = True,\n",
    "                        laminar_summary = False, tracer_category = 'wild_type',\n",
    "                        selected_tracer = 46)\n",
    "MesoPred.PlotStatistics(Code, structure_summary = True,\n",
    "                        laminar_summary = False, tracer_category = 'gene module',\n",
    "                        selected_tracer = 118)\n",
    "MesoPred.PlotStatistics(Code, structure_summary = True,\n",
    "                        laminar_summary = False, tracer_category = 'gene module',\n",
    "                        selected_tracer = 46)\n",
    "MesoPred.PlotStatistics(Code, structure_summary = True,\n",
    "                        laminar_summary = False, tracer_category = 'gene module',\n",
    "                        selected_tracer = 117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_tracer = [idx for idx,val in enumerate(MesoPred.ConDict['wild_type']['structure-abbrev']) if val == 'PAA'][0]\n",
    "BP_25 = PL.BrainPlotter(resolution = 25)\n",
    "BP_10 = PL.BrainPlotter(resolution = 10)\n",
    "BP_25.fit(projection = ClfResults_ridge['wild_type']['y_actual'][:,sel_tracer], \n",
    "          chosen_indices = MesoPred.params['remaining_indices'])\n",
    "BP_10.fit(projection = ClfResults_ridge['wild_type']['y_actual'][:,sel_tracer], \n",
    "          chosen_indices = MesoPred.params['remaining_indices'])\n",
    "\n",
    "BP_25.plot_slice(savefile = 'paper1_figures/brain_slice_wild_type_{}.jpg'.format(sel_tracer))\n",
    "BP_10.plot_flatmap(savefile = 'paper1_figures/flatmap_wild_type_{}.jpg'.format(sel_tracer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_tracer = [idx for idx,val in enumerate(MesoPred.ConDict['wild_type']['structure-abbrev']) if val == 'PAA'][0]\n",
    "for modulo in [46,117,118]:\n",
    "    rho,pval = sci.stats.pearsonr(Code[:,modulo],ClfResults_ridge['wild_type']['y_actual'][:,sel_tracer])\n",
    "    print rho, modulo\n",
    "    BP_25 = PL.BrainPlotter(resolution = 25)\n",
    "    BP_10 = PL.BrainPlotter(resolution = 10)\n",
    "    BP_25.fit(projection = Code[:,modulo], chosen_indices = MesoPred.params['remaining_indices'])\n",
    "    BP_10.fit(projection = Code[:,modulo], chosen_indices = MesoPred.params['remaining_indices'])\n",
    "    BP_25.plot_slice()\n",
    "    BP_10.plot_flatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_tracer = [idx for idx,val in enumerate(MesoPred.ConDict['wild_type']['structure-abbrev']) if val == 'PAA'][0]\n",
    "for code in range(len(G_Code[0])):\n",
    "    rho = sci.stats.pearsonr(ClfResults_ridge['wild_type']['y_actual'][:,sel_tracer], G_Code[:,code])[0]\n",
    "    if rho > 0.2:\n",
    "        print code\n",
    "        BP_25 = PL.BrainPlotter(resolution = 25)\n",
    "        BP_10 = PL.BrainPlotter(resolution = 10)\n",
    "        BP_25.fit(projection = G_Code[:,code], chosen_indices = MesoPred.params['remaining_indices'])\n",
    "        BP_10.fit(projection = G_Code[:,code], chosen_indices = MesoPred.params['remaining_indices'])\n",
    "        BP_25.plot_slice(savefile = 'paper1_figures/grange_brain_slice_module_{}.jpg'.format(code))\n",
    "        BP_10.plot_flatmap(savefile = 'paper1_figures/grange_flatmap_module_{}.jpg'.format(code))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I assess the decomposition quality of DLSC by chosing different set sizes and predicting the tract tracing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Store_now = {'scores': [], 'comp' : []}\n",
    "Comp_set = [10,25,50,100,150,200,250,300,400,500,1000]\n",
    "ridge_params = {'alpha': [1,10,100,250,500,1000],\n",
    "                     'fit_intercept' : [True], 'normalize' : [False]}\n",
    "\n",
    "for comp in Comp_set:\n",
    "    Atoms, Code, dlsc = MesoPred.DictionaryDecomposition(ClfResults_ridge['wild_type']['Gene Expression'], \n",
    "                                                         n_comp = comp)\n",
    "    ridge_pred = {}\n",
    "    for key in ClfResults_ridge.keys():\n",
    "        module_to_proj = []\n",
    "        y_pred = np.zeros(np.shape(ClfResults_ridge[key]['y_actual']))\n",
    "        Code_scale = StandardScaler().fit_transform(Code) \n",
    "        y_meas_scale = StandardScaler().fit_transform(ClfResults_ridge[key]['y_actual'])\n",
    "        for train, test in MesoPred.params['validation'].split(Code,ClfResults_ridge[key]['y_actual']):\n",
    "            ridge_mdl = GridSearchCV(Ridge(), param_grid = ridge_params, \n",
    "                                 scoring = 'neg_mean_squared_error', \n",
    "                                 cv = 3, n_jobs = -1)\n",
    "            ridge_mdl.fit(Code_scale[train], y_meas_scale[train])\n",
    "            y_pred[test] = ridge_mdl.predict(Code_scale[test]) \n",
    "        ridge_pred[key] = metrics.r2_score(y_meas_scale, y_pred, multioutput = 'raw_values')\n",
    "    all_scores = np.asarray([tracer for key in ridge_pred.keys()\\\n",
    "                                           for tracer in ridge_pred[key]])   \n",
    "    print comp, np.max(all_scores), np.min(all_scores), np.median(all_scores)\n",
    "    Store_now['scores'].append(all_scores)\n",
    "\n",
    "            \n",
    "scores   = [np.median(val) for val in Store_now['scores']]\n",
    "coef_num = [str(val) for val in Comp_set]\n",
    "coef_num.pop(6)\n",
    "pk.dump([scores,coef_num],open('paper1_figures/dictionary_to_performance.pkl','wb'))\n",
    "\n",
    "#[scores,coef_num] = pk.load(open('paper1_figures/dictionary_to_performance.pkl','rb'))\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.bar(coef_num, scores)\n",
    "ax = plt.gca(); ax.xaxis.set_tick_params(labelsize = 16); ax.yaxis.set_tick_params(labelsize = 16)\n",
    "plt.ylabel(r'median $r^2$',fontsize = 18)\n",
    "plt.xlabel('dictionary set size', fontsize = 18)\n",
    "plt.savefig('paper1_figures/dictionary_to_performance.jpg')\n",
    "plt.savefig('paper1_figures/dictionary_to_performance.eps')\n",
    "print scores\n",
    "print coef_num        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I make a prediction-derived scatter plot where I colorcode subcortical and cortical projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['Cux2-IRES-Cre']:\n",
    "    top_tracer = np.argsort(ClfResults_ridge[key]['r2'])[1][0]\n",
    "    print top_tracer, ClfResults_ridge[key]['r2'][top_tracer], MesoPred.ConDict[key]['structure-abbrev'][top_tracer]\n",
    "    \n",
    "A = ClfResults_ridge[key]['y_actual'][:,top_tracer]\n",
    "B = ClfResults_ridge[key]['y_preds'][:,top_tracer]\n",
    "laminar_profs = [MesoPred.targetprofiles['alt laminar profiles'][val] for val in MesoPred.params['remaining_indices']]\n",
    "\n",
    "resids              = abs(A-B)\n",
    "\n",
    "remaining_indices   = np.asarray([MesoPred.targetprofiles['str_acronym'][val] for val in MesoPred.params['remaining_indices']])\n",
    "subcortical_indices = [idx for idx,val in enumerate(laminar_profs) \n",
    "                       if val == 'layer inspecific' or val == 'other profiles']\n",
    "cortical_indices    = [idx for idx,val in enumerate(laminar_profs) \n",
    "                       if val != 'layer inspecific' and val != 'other profiles']\n",
    "\n",
    "subcortical_bad     = remaining_indices[subcortical_indices][np.argsort(resids[subcortical_indices])[::-1][0:50]]\n",
    "subcortical_good    = remaining_indices[subcortical_indices][np.argsort(resids[subcortical_indices])[0:50]]\n",
    "cortical_bad        = remaining_indices[cortical_indices][np.argsort(resids[cortical_indices])[::-1][0:10]]\n",
    "cortical_good       = remaining_indices[cortical_indices][np.argsort(resids[cortical_indices])[0:10]]\n",
    "\n",
    "from scipy.stats import zscore\n",
    "A = zscore(A); A = np.array(A,np.float16)\n",
    "B = zscore(B); B = np.array(B,np.float16)\n",
    "\n",
    "v_min = min(np.min(A),np.min(B))\n",
    "v_max = max(np.max(A),np.max(B))\n",
    "\n",
    "plt.figure(figsize = (15,12))\n",
    "#plt.xticks(np.arange(-0.1,1.05,0.1))\n",
    "#plt.yticks(np.arange(-0.1,1.05,0.1))\n",
    "plt.xticks(np.arange(np.round(v_min)-0.2,np.round(v_max)+0.2,0.2))\n",
    "plt.yticks(np.arange(np.round(v_min)-0.2,np.round(v_max)+0.2,0.2))\n",
    "\n",
    "plt.scatter(A[subcortical_indices],B[subcortical_indices], c = 'g')\n",
    "plt.legend()\n",
    "plt.scatter(A[cortical_indices],B[cortical_indices], c = 'r')\n",
    "plt.legend(['subcortical projections','cortical projections'],loc=\"lower right\", prop={'size': 28})\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 22, rotation = 45) #290\n",
    "ax.yaxis.set_tick_params(labelsize = 22)\n",
    "#plt.axis('scaled')\n",
    "plt.xlabel('Normalized projection volume (measured)', fontsize = 28)\n",
    "plt.ylabel('Normalized projection volume (predicted)', fontsize = 28)\n",
    "plt.title('Cux2-IRES-Cre AId', fontsize = 28)\n",
    "\n",
    "plt.plot((v_min,v_max),(v_min,v_max))\n",
    "#plt.plot((0,1),(0,1))\n",
    "plt.savefig('paper1_figures/scatter_plot_for_aid.tiff',  bbox_inches = 'tight')\n",
    "plt.savefig('paper1_figures/scatter_plot_for_aid.eps',  bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r2 and AURoc Validation for all gene expression-based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_ridge = [list(pred) for key in MesoPred.ConDict.keys() for pred in ClfResults_ridge[key]['r2']]\n",
    "team_auc = [list(pred) for key in MesoPred.ConDict.keys() for pred in ClfResults_ridge[key]['AURoc']]\n",
    "\n",
    "plt.scatter(team_ridge, team_auc)\n",
    "plt.plot((0,1),(0,1))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 32)\n",
    "ax.yaxis.set_tick_params(labelsize = 32)\n",
    "plt.xlabel('AURoC values', fontsize = 34)\n",
    "plt.ylabel(r'$r^2$ values', fontsize = 34)\n",
    "plt.title('Scatter Plot', fontsize = 34)\n",
    "plt.savefig('paper1_figures/r2_to_auc.jpg')\n",
    "plt.savefig('paper1_figures/r2_to_auc.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.boxplot(team_auc)\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_tick_params(labelsize = 20)\n",
    "plt.ylabel('AURoc values', fontsize = 30)\n",
    "plt.xlabel('Ridge Regression', fontsize = 30)\n",
    "ax.yaxis.set_tick_params(labelsize = 20)\n",
    "plt.yticks(np.arange(0.7,1.0,0.05))\n",
    "plt.savefig('Total_AUC.eps')\n",
    "plt.show()\n",
    "\n",
    "total_performance = OrderedDict()\n",
    "for key in ClfResults_ridge.keys():\n",
    "    total_performance[key] = np.median(np.ndarray.flatten(np.asarray([val for val in ClfResults_ridge[key]['AURoc']])))\n",
    "\n",
    "import operator\n",
    "srt_total_performance = sorted(total_performance.items(), key=operator.itemgetter(1))[::-1] \n",
    "pk.dump(srt_total_performance, open('auc_srt_total_performance.pkl','wb')) \n",
    "#srt_total_performance = pk.load(open('auc_srt_total_performance.pkl','rb'))\n",
    "\n",
    "tmp = [val[1] for val in srt_total_performance]\n",
    "fig = plt.figure(figsize = (35,12))\n",
    "ax  = plt.gca()\n",
    "bara = plt.bar([val[0] for val in srt_total_performance], tmp, bottom = 0, align = 'center', \n",
    "        linewidth = 0.4, width = 0.6) \n",
    "bara.patches[3].set_facecolor('red')\n",
    "ax.plot([-0.5, 14.5], [np.min(tmp), np.min(tmp)], \"k--\")\n",
    "plt.xticks(rotation = -20)\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "ax.xaxis.set_tick_params(labelsize = 24)\n",
    "ax.yaxis.set_tick_params(labelsize = 36)\n",
    "#plt.tight_layout()\n",
    "plt.title('Median predictive performance per cre-line', fontsize = 36)\n",
    "plt.ylabel('area under the ROC curve', fontsize = 36)\n",
    "plt.savefig('paper1_figures/total_auc.jpg')\n",
    "plt.savefig('paper1_figures/total_auc.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(team_ridge)\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_tick_params(labelsize = 20)\n",
    "plt.ylabel(r'$r^2$ values', fontsize = 30)\n",
    "plt.xlabel('Ridge Regression', fontsize = 30)\n",
    "ax.yaxis.set_tick_params(labelsize = 20)\n",
    "plt.yticks(np.arange(0.7,1.0,0.05))\n",
    "plt.savefig('Total_r2.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cre_res = [r2 for key,value in ClfResults_ridge.items() for r2 in value['r2'] if key != 'wild_type']\n",
    "input_data = [cre_res,ClfResults_ridge['wild_type']['r2']]\n",
    "intitle = 'Performance comparison between cre-line and wild-type data'\n",
    "Custom_Boxplot(input_data, savename = 'paper1_figures/r2_cre_vs_wt', title = intitle, \n",
    "               ylabel = r'$r^2$', xticklabel = ['cre-line','wild_type'],\n",
    "               inrange = [0,1.05,0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I run a statistical test to measure the significance of variability in performance between cre-line and wild-type data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 1000\n",
    "srt_total_performance = pk.load(open('r2_srt_total_performance.pkl','rb'))\n",
    "total_cre_r2 = [tmp[1] for tmp in srt_total_performance if tmp[0] != 'wild_type']\n",
    "sample_size_sets = [len(ClfResults_ridge[key]['y_actual'][0]) for key in ClfResults_ridge.keys() if key != 'wild_type']\n",
    "cre_median = np.median(total_cre_r2); cre_iqr = sci.stats.iqr(total_cre_r2)\n",
    "wt_size = np.shape(ClfResults_ridge['wild_type']['y_actual'])[1]\n",
    "\n",
    "cnt1 = 0; cnt2 = 0; med_dev = []; iqr_dev = []\n",
    "#for sample_set in sample_size_sets:\n",
    "for key in ClfResults_ridge.keys(): \n",
    "    if key == 'wild_type': continue\n",
    "    sample_set = np.shape(ClfResults_ridge[key]['y_actual'])[1]\n",
    "    for sample_run in range(sample_num):\n",
    "        wt_subset = np.random.choice(wt_size, sample_set)\n",
    "        A = ClfResults_ridge['wild_type']['y_actual'][:,wt_subset]\n",
    "        B = ClfResults_ridge['wild_type']['y_preds'][:,wt_subset]\n",
    "        wt_r2_sub = metrics.r2_score(A,B)\n",
    "        #if np.max(wt_r2_sub) > np.max(total_cre_r2) or np.min(wt_r2_sub) < np.min(total_cre_r2):\n",
    "        #if wt_r2_sub > np.max(total_cre_r2) or wt_r2_sub < np.min(total_cre_r2): \n",
    "        #print wt_r2_sub, cre_median + 1*cre_iqr, cre_median - 1*cre_iqr\n",
    "        if wt_r2_sub > cre_median + 1*cre_iqr or wt_r2_sub < cre_median - 1*cre_iqr:  \n",
    "            cnt1 += 1\n",
    "            \n",
    "print cnt1/(1.0*len(sample_size_sets)*sample_num), len(sample_size_sets)*sample_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Testing of CCP (Gene Expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ClfResults_ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7a009b0f48ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                 'normalize': [False]}\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mClfResults_ridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mConStr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ConMat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ClfResults_ridge' is not defined"
     ]
    }
   ],
   "source": [
    "ridge_params = {'alpha': [10.0,100.0,1000.0,10000.0, 100000.0, 10e6,10e12],'fit_intercept': [True],\n",
    "                'normalize': [False]}\n",
    "\n",
    "for key in ClfResults_ridge.keys():\n",
    "    print key\n",
    "    ConStr = ConDict[key]['ConMat']\n",
    "    GeneExp_proc, sc_gene_exp, ConStr_proc, sc_sqrt = MesoPred.PreProcessing(\n",
    "                                                                GeneExp[MesoPred.params['leaf_keys'],:], \n",
    "                                                                MesoPred.params, \n",
    "                                                                ConStr[MesoPred.params['leaf_keys'],:])\n",
    "    \n",
    "    y_pred = np.zeros(np.shape(ConStr_proc))\n",
    "    for prm_num in range(25):\n",
    "        ConStr_sqrt_ctr_prm = np.random.permutation(ConStr_proc)\n",
    "        cnt = 0\n",
    "        for train, test in MesoPred.params['validation'].split(GeneExp_proc,ConStr_sqrt_ctr_prm):\n",
    "            cnt += 1\n",
    "            surrogate_mdl = GridSearchCV(Ridge(), param_grid = ridge_params, \n",
    "                                         scoring = 'neg_mean_squared_error', \n",
    "                                         cv = 3, n_jobs = -1)\n",
    "            surrogate_mdl.fit(GeneExp_proc[train], ConStr_sqrt_ctr_prm[train])\n",
    "            y_pred[test] = surrogate_mdl.predict(GeneExp_proc[test])\n",
    "\n",
    "        ridge_pred = metrics.r2_score(ConStr_sqrt_ctr_prm, y_pred, multioutput = 'raw_values')\n",
    "        print np.mean(ridge_pred)\n",
    "        plt.scatter(np.ndarray.flatten(ConStr_sqrt_ctr_prm),np.ndarray.flatten(y_pred))\n",
    "        plt.show()\n",
    "        #ridge_pred  = CustomCrossval(params['primary models'][6], MesoPred.GeneExp, ConStr_sqrt_ctr_prm, params['validation'][1])\n",
    "        #ClfResults_ridge = MesoPred.UnravelResults(ridge_pred, params, sc_sqrt)\n",
    "\n",
    "        pk.dump([y_pred, ConStr_sqrt_ctr_prm], open('scrambled_debug/' + 'regression'+ '_'+ MesoPred.params['cre-line'] +'_ridge_pred' + str(prm_num) + '.pkl','wb'))\n",
    "        pk.dump(ridge_pred, open('scrambled_debug/' + key + '_all_results' + str(prm_num) + '_ridge.pkl', 'wb'))\n",
    "        print 'Ridge regression num ' + str(prm_num) + ' has been completed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression outperforms Random Forest with a median r2 score over all 1397 tracers of 0.54 instead of 0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_rf    = [list(pred) for key in MesoPred.ConDict.keys() for pred in ClfResults['random forest'][key]['r2']]\n",
    "team_ridge = [list(pred) for key in MesoPred.ConDict.keys() for pred in ClfResults_ridge['ridge'][key]['r2']]\n",
    "print np.median(team_rf),np.median(team_ridge), sci.stats.iqr(team_rf), sci.stats.iqr(team_ridge)\n",
    "JoinResults = np.asarray([(a[0],b[0]) for a,b in zip(team_ridge, team_rf)])\n",
    "pk.dump(JoinResults, open('paper1_figures/rf_ridge_Results.pkl','wb'))\n",
    "#JoinResults = pk.load(open('paper1_figures/rf_ridge_Results.pkl','rb'))\n",
    "\n",
    "fig = plt.figure(figsize = (35,15))\n",
    "ax = plt.gca()\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "box = plt.boxplot(JoinResults,0, 'gD', widths = 0.6, whis = [5,95])\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.rcParams['figure.figsize']\n",
    "plt.ylabel(r'$r^2$', fontsize = 36)\n",
    "plt.xticks([i+1 for i in range(2)], ['Ridge Regression','Random Forest'],rotation = 0)\n",
    "ax.xaxis.set_tick_params(labelsize = 36)\n",
    "ax.yaxis.set_tick_params(labelsize = 36)\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "for key in box.keys():\n",
    "    for bp in box[key]:\n",
    "        bp.set(linewidth = 2.5)\n",
    "plt.savefig('paper1_figures/Ridge Regression - Random Forest comparison.eps')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "#JoinResults = pk.load(open('paper1_figures/rf_ridge_Results.pkl','rb'))\n",
    "Custom_Boxplot(JoinResults, savename = 'paper1_figures/Ridge Regression - Random Forest comparison', \n",
    "               ylabel = r'$r^2$', xticklabel = ['Ridge Regression','Random Forest'],\n",
    "               inrange = [0,1.05,0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the NaN frequency of the unionized gene expression and normalized projection volume data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.asarray(MesoPred.ConDict['wild_type']['ConMat'])\n",
    "pk.dump(B, open('paper1_figures/ConMat_for_hist.pkl','wb'))\n",
    "\n",
    "#B = pk.load(open('/home/ntimonidis/knoppers/Nestor/venv/paper1_figures/ConMat_for_hist.pkl','rb'))\n",
    "B = B[MesoPred.params['leaf_keys'],:]\n",
    "nan_freq = [len(con_area[np.isnan(con_area)])/(1.0*len(con_area)) for idx, con_area in enumerate(B)]\n",
    "group_1 = len([val for val in nan_freq if val < 0.1])\n",
    "group_2 = len([val for val in nan_freq if val > 0.8])\n",
    "plt.figure(figsize = (12,6))\n",
    "#plt.hist(np.asarray(nan_freq))\n",
    "group_labels = ['less than 10%','more than 80%']\n",
    "plt.bar(group_labels,[group_1,group_2])\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 18)\n",
    "ax.yaxis.set_tick_params(labelsize = 18)\n",
    "plt.ylabel('frequency of brain regions', fontsize = 20)\n",
    "plt.xlabel('frequency of nan values per region', fontsize = 20)\n",
    "plt.savefig('paper1_figures/nan_histogram2.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.asarray(GeneExp)\n",
    "nan_freq = [len(gene_area[np.isnan(gene_area)])/(1.0*len(gene_area)) for idx, gene_area in enumerate(A)]\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.hist(np.asarray(nan_freq))\n",
    "plt.ylabel('frequency of brain regions', fontsize = 12)\n",
    "plt.xlabel('frequency of nan values per region', fontsize = 12)\n",
    "plt.savefig('paper1_figures/nan_histogram.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame(data = np.asarray(GeneExp))\n",
    "pk.dump(df, open('paper1_figures/nan_gene_mat.pkl','wb'))\n",
    "#df = pk.load(open('paper1_figures/nan_gene_mat.pkl','rb'))\n",
    "\n",
    "sns.heatmap(df, yticklabels = [], xticklabels = [])\n",
    "sns.set(rc={'figure.figsize':(30,15.27)},font_scale = 2.3)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 20)\n",
    "ax.yaxis.set_tick_params(labelsize = 20)\n",
    "plt.xticks(rotation = 290)\n",
    "plt.xlabel('Genes', fontsize = 40)\n",
    "plt.ylabel('Brain Areas', fontsize = 40)\n",
    "#plt.savefig('paper1_figures/nan_gene_heatmap.jpg')\n",
    "plt.savefig('paper1_figures/nan_gene_heatmap.eps')\n",
    "#plt.savefig('paper1_figures/nan_gene_heatmap.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConStr = MesoPred.ConDict['wild_type']['ConMat']\n",
    "ConStr_im = ConStr[MesoPred.params['leaf_keys'],:]; GeneExp_im = GeneExp[MesoPred.params['leaf_keys'],:]\n",
    "ConStr_im,nanCons = PL.RemoveNanStructs(0,0.1).fit(ConStr_im)\n",
    "GeneExp_im = np.delete(GeneExp_im,nanCons,0)\n",
    "GeneExp_im,nanGenes = PL.RemoveNanStructs(0,0.03).fit(GeneExp_im)\n",
    "ConStr_im = np.delete(ConStr_im,nanGenes,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_acros = [MesoPred.targetprofiles['str_acronym'][val] for val in MesoPred.params['remaining_indices']]\n",
    "import seaborn as sns\n",
    "df = pd.DataFrame(data = np.asarray(GeneExp_im), index = reduced_acros, columns = MesoPred.params['Gene Acronyms'])\n",
    "pk.dump(df, open('paper1_figures/imputed_gene_mat.pkl','wb'))\n",
    "#df = pk.load(open('paper1_figures/imputed_gene_mat.pkl','rb'))\n",
    "\n",
    "sns.set(rc={'figure.figsize':(30,15.27)},font_scale = 2.3)\n",
    "sns.heatmap(df, yticklabels = [], xticklabels = [])\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 20)\n",
    "ax.yaxis.set_tick_params(labelsize = 20)\n",
    "plt.xticks(rotation = 290)\n",
    "plt.xlabel('Genes', fontsize = 40)\n",
    "plt.ylabel('Brain Areas', fontsize = 40)\n",
    "#plt.savefig('paper1_figures/nan_gene_imputation_1.jpg')\n",
    "plt.savefig('paper1_figures/nan_gene_imputation_1.eps')\n",
    "#plt.savefig('paper1_figures/nan_gene_imputation_1.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "temp_mat  = []\n",
    "acros     = []\n",
    "genes     = []\n",
    "sel_genes = []\n",
    "sel_acros = []\n",
    "\n",
    "red_strs = [MesoPred.params['acronyms'][val] for val in MesoPred.params['remaining_indices']]\n",
    "anc = FL.GetAncestor(red_strs,mode = 'acro')\n",
    "\n",
    "for row,area in enumerate(GeneExp_im):\n",
    "    for col, gene in enumerate(area):\n",
    "        if mt.isnan(gene) == True:\n",
    "            if col not in sel_genes and MesoPred.params['Gene Acronyms'][col] not in sel_genes:\n",
    "                cnt = cnt + 1\n",
    "                genes.append(col)\n",
    "                sel_genes.append(MesoPred.params['Gene Acronyms'][col])\n",
    "            if row not in acros and red_strs[row] not in sel_acros and anc.values()[row] == 'CTX': \n",
    "                cnt = cnt + 1\n",
    "                acros.append(row)\n",
    "                sel_acros.append(red_strs[row])\n",
    "        if cnt > 10:\n",
    "            break\n",
    "\n",
    "cnt = 0            \n",
    "for element in range(len(red_strs)): \n",
    "    if anc.values()[element] == 'CTX':\n",
    "        cnt+=1\n",
    "        if red_strs[element] not in sel_acros:\n",
    "            sel_acros.append(red_strs[element])\n",
    "            acros.append(element)\n",
    "        if MesoPred.params['Gene Acronyms'][element] not in sel_genes:\n",
    "            genes.append(element)\n",
    "            sel_genes.append(MesoPred.params['Gene Acronyms'][element]) \n",
    "        if cnt == 10:\n",
    "            break\n",
    "\n",
    "acros = np.asarray(acros)\n",
    "genes = np.asarray(genes)  \n",
    "sel_genes = np.asarray(sel_genes); sel_acros = np.asarray(sel_acros)\n",
    "gene_idx = np.argsort(sel_genes); target_idx = np.argsort(sel_acros)\n",
    "sel_genes = sel_genes[gene_idx]; sel_acros = sel_acros[target_idx]\n",
    "acros = acros[target_idx]; genes = genes[gene_idx]\n",
    "print genes,sel_genes\n",
    "print acros, sel_acros\n",
    "\n",
    "tracer2 = []; sel_tracer = []\n",
    "cnt = 0\n",
    "for row,area in enumerate(acros):\n",
    "    for inj in range(len(ConStr_im)):\n",
    "        if mt.isnan(ConStr_im[area,inj]) == True:\n",
    "            if col not in tracer2 and MesoPred.ConDict['wild_type']['structure-abbrev'][inj] not in sel_tracer:\n",
    "                cnt += 1\n",
    "                tracer2.append(inj)\n",
    "                sel_tracer.append(MesoPred.ConDict['wild_type']['structure-abbrev'][inj])\n",
    "        else:\n",
    "            if cnt > 0 and MesoPred.ConDict['wild_type']['structure-abbrev'][inj] not in sel_tracer:\n",
    "                sel_tracer.append(MesoPred.ConDict['wild_type']['structure-abbrev'][inj])\n",
    "                tracer2.append(inj)\n",
    "                cnt+=1\n",
    "        if cnt > 10:\n",
    "            break \n",
    "\n",
    "A = GeneExp_im[acros,:]\n",
    "B = A[:,genes]\n",
    "GeneExp_im2 = Imputer(missing_values = 'NaN', strategy = 'median', axis = 0, verbose=0, copy=True).fit_transform(GeneExp_im)\n",
    "A2 = GeneExp_im2[acros,:]\n",
    "B2 = A2[:,genes]\n",
    "\n",
    "A1 = ConStr_im[acros,:]\n",
    "B1 = A1[:,tracer2] \n",
    "A3 = ConStr_im[acros,:]\n",
    "B1 = A1[:,tracer2]\n",
    "\n",
    "B3 = np.copy(B1)\n",
    "for task in range(len(B1[0])):\n",
    "    nans = [idx for idx,val in enumerate(B1[:,task]) if mt.isnan(val) == True]\n",
    "    if len(nans) > 0:\n",
    "        B3[:,task] = PL.BimodalImputation().fit(B3[:,task])\n",
    "        \n",
    "clear_output() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_im = pd.DataFrame(data = np.power(B, 1./3), index = sel_acros, columns = sel_genes)\n",
    "pk.dump(df_im, open('paper1_figures/nan_gene_submat.pkl','wb'))\n",
    "df_im2 = pd.DataFrame(data = np.power(B2, 1./3), index = sel_acros,columns = sel_genes)\n",
    "pk.dump(df_im2, open('paper1_figures/imputed_gene_submat.pkl','wb'))\n",
    "df_im3 = pd.DataFrame(data = np.power(B1, 1./3), index = sel_acros, columns = sel_tracer)\n",
    "df_im4 = pd.DataFrame(data = np.power(B3, 1./3), index = sel_acros, columns = sel_tracer)\n",
    "df_im5 = pd.DataFrame(data = StandardScaler().fit_transform(np.power(B2, 1./3)), \n",
    "                      index = sel_acros, columns = sel_genes)\n",
    "df_im6 = pd.DataFrame(data = StandardScaler().fit_transform(np.power(B3, 1./3)), \n",
    "                      index = sel_acros, columns = sel_tracer)\n",
    "\n",
    "#df_im = pk.load(open('paper1_figures/nan_gene_submat.pkl','rb'))\n",
    "#df_im2 = pk.load(open('paper1_figures/imputed_gene_submat.pkl','rb'))\n",
    "max_val = max(df_im.max().max(), df_im2.max().max())\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 26)\n",
    "ax.yaxis.set_tick_params(labelsize = 26)\n",
    "sns.set(rc={'figure.figsize':(30,15.27)},font_scale = 2.2)\n",
    "sns.heatmap(df_im, vmin = 0, vmax = max_val)\n",
    "plt.xticks(rotation = 290)\n",
    "plt.xlabel('Genes', fontsize = 32)\n",
    "plt.ylabel('Target Areas', fontsize = 32)\n",
    "plt.savefig('paper1_figures/nan_gene_imputed_step1.tiff', bbox_inches = 'tight')\n",
    "plt.savefig('paper1_figures/nan_gene_imputed_step1.eps', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 26)\n",
    "ax.yaxis.set_tick_params(labelsize = 26)\n",
    "sns.set(rc={'figure.figsize':(30,15.27)}, font_scale = 2.2)\n",
    "sns.heatmap(df_im2, vmin = 0, vmax = max_val)\n",
    "plt.xticks(rotation = 290)\n",
    "plt.xlabel('Genes', fontsize = 32)\n",
    "plt.ylabel('Target Areas', fontsize = 32)\n",
    "plt.savefig('paper1_figures/nan_gene_imputed_step2.tiff', bbox_inches = 'tight')\n",
    "plt.savefig('paper1_figures/nan_gene_imputed_step2.eps', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "max_val = max(df_im3.max().max(), df_im4.max().max())\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 26)\n",
    "ax.yaxis.set_tick_params(labelsize = 26)\n",
    "sns.set(rc={'figure.figsize':(30,15.27)}, font_scale=2.2)\n",
    "sns.heatmap(df_im3, vmin=0, vmax = max_val)\n",
    "plt.xticks(rotation = 290)\n",
    "plt.xlabel('Source Areas', fontsize = 32)\n",
    "plt.ylabel('Target Areas', fontsize = 32)\n",
    "plt.savefig('paper1_figures/nan_con_imputed_step1.tiff', bbox_inches = 'tight')\n",
    "plt.savefig('paper1_figures/nan_con_imputed_step1.eps', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "#df_im2 = pd.DataFrame(data = np.power(B2, 1./3), index = sel_acros2, columns = sel_tracer)\n",
    "#pk.dump(df_im2, open('paper1_figures/imp_con_submat.pkl','wb'))\n",
    "#df_im2 = pk.load(open('paper1_figures/imp_con_submat.pkl','rb'))\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 26)\n",
    "ax.yaxis.set_tick_params(labelsize = 26)\n",
    "sns.set(rc={'figure.figsize':(30,15.27)}, font_scale = 2.3)\n",
    "sns.heatmap(df_im4, vmin=0, vmax = max_val)\n",
    "plt.xticks(rotation = 290)\n",
    "plt.xlabel('Source Areas', fontsize = 32)\n",
    "plt.ylabel('Target Areas', fontsize = 32)\n",
    "plt.savefig('paper1_figures/nan_con_imputed_step2.tiff', bbox_inches = 'tight')\n",
    "plt.savefig('paper1_figures/nan_con_imputed_step2.eps', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "#pk.dump(df_im, open('paper1_figures/zscore_gene_submat.pkl','wb'))\n",
    "#df_im = pk.load(open('paper1_figures/zscore_gene_submat.pkl','rb'))\n",
    "v_min = min(df_im5.min().min(),df_im6.min().min())\n",
    "v_max = min(df_im5.max().max(),df_im6.max().max())\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 26)\n",
    "ax.yaxis.set_tick_params(labelsize = 26)\n",
    "sns.set(rc={'figure.figsize':(30,15.27)}, font_scale = 2.2)\n",
    "sns.heatmap(df_im5, vmin = v_min, vmax = v_max)\n",
    "plt.xticks(rotation = 290)\n",
    "plt.xlabel('Genes', fontsize = 32)\n",
    "plt.ylabel('Target Areas', fontsize = 32)\n",
    "plt.savefig('paper1_figures/gene_exp_zscored.tiff', bbox_inches = 'tight')\n",
    "plt.savefig('paper1_figures/gene_exp_zscored.eps', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "#df_im2 = pk.load(open('paper1_figures/zscore_con_submat.pkl','rb'))\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 26)\n",
    "ax.yaxis.set_tick_params(labelsize = 26)\n",
    "sns.set(rc={'figure.figsize':(30,15.27)},font_scale = 2.3)\n",
    "sns.heatmap(df_im6, vmin = v_min, vmax = v_max)\n",
    "plt.xticks(rotation = 290)\n",
    "plt.xlabel('Source Areas', fontsize = 32)\n",
    "plt.ylabel('Target Areas', fontsize = 32)\n",
    "plt.savefig('paper1_figures/con_zscored.tiff', bbox_inches = 'tight')\n",
    "plt.savefig('paper1_figures/con_zscored.eps', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConStr_im2 = B3\n",
    "pk.dump([ConStr_im2,ConStr_sqrt,GeneExp_im2,GeneExp_cube], open('paper1_figures/skewness_with_transformation.pkl','wb'))\n",
    "\n",
    "#[ConStr_im2,ConStr_sqrt,GeneExp_im2,GeneExp_cube] = pk.load(open('/home/ntimonidis/knoppers/Nestor/venv/paper1_figures/skewness_with_transformation.pkl','rb'))\n",
    "plt.figure(figsize = (12,6))\n",
    "rwidth = 1.0\n",
    "bins = 20\n",
    "fig, axs = plt.subplots(2, 2, sharey = False, sharex = False, figsize=(44,24))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 32)\n",
    "ax.yaxis.set_tick_params(labelsize = 32)\n",
    "plt.setp(axs, xticks = np.arange(-4,22,1))\n",
    "axs[0,0].hist(sci.stats.skew(ConStr_im2), bins = bins, rwidth = rwidth, range = (-3,21), align = 'mid', histtype = 'bar', ec='black')\n",
    "axs[0,0].set_xticks(np.arange(-3,21,1))\n",
    "axs[0,0].set_ylabel('number of tracing experiments', fontsize = 36)\n",
    "axs[0,0].tick_params(axis = \"y\", labelsize = 34)\n",
    "axs[0,0].tick_params(axis = \"x\", labelsize = 32)\n",
    "#axs[0,1].title('Skewness distribution before transformation - Wild-type tracers')\n",
    "#plt.figure(figsize = (12,6))\n",
    "axs[0,1].hist(sci.stats.skew(ConStr_sqrt), bins = bins, rwidth = rwidth, range = (-3,21), align = 'mid', histtype = 'bar', ec='black')\n",
    "axs[0,1].set_xticks(np.arange(-3,21,1))\n",
    "axs[0,1].tick_params(axis = \"y\", labelsize = 34)\n",
    "axs[0,1].tick_params(axis = \"x\", labelsize = 32)\n",
    "axs[1,0].hist(sci.stats.skew(GeneExp_im2), bins = bins, rwidth = rwidth, range = (-3,21), align = 'mid', histtype = 'bar', ec='black')\n",
    "axs[1,0].set_xticks(np.arange(-3,21,1))\n",
    "axs[1,0].set_ylabel('number of genes', fontsize = 36)\n",
    "axs[1,0].set_xlabel('skewness values', fontsize = 36)\n",
    "axs[1,0].tick_params(axis = \"y\", labelsize = 34)\n",
    "axs[1,0].tick_params(axis = \"x\", labelsize = 32)\n",
    "#plt.title('Skewness distribution before transformation - Gene Expression')\n",
    "#plt.figure(figsize = (12,6))\n",
    "axs[1,1].hist(sci.stats.skew(GeneExp_cube), bins = bins, rwidth = rwidth, range = (-3,21), align = 'mid', histtype = 'bar', ec='black')\n",
    "axs[1,1].set_xticks(np.arange(-3,21,1))\n",
    "axs[1,1].tick_params(axis = \"y\", labelsize = 34)\n",
    "axs[1,1].set_xlabel('skewness values', fontsize = 36)\n",
    "#plt.title('Skewness distribution after transformation - Gene Expression')\n",
    "\n",
    "plt.savefig('paper1_figures/Skewness_with_transformation.tiff', bbox_inches = 'tight')\n",
    "plt.savefig('paper1_figures/Skewness_with_transformation.eps', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subcortical and Cortical visualizations of highly predicted projection volumes and their measured counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer_list = list(ClfResults_ridge.keys())\n",
    "other_scores = np.asarray([(key,tracer) for key in ClfResults_ridge.keys() for tracer,score in enumerate(ClfResults_ridge[key]['r2']) if score > 0.8])\n",
    "max_r = np.asarray([(np.argmax(ClfResults_ridge[key]['r2']),np.max(ClfResults_ridge[key]['r2'])) for key in ClfResults_ridge.keys()])\n",
    "tracer_category = tracer_list[np.argmax(max_r[:,1])]\n",
    "tracer_num = int(max_r[np.argmax(max_r[:,1]),0])\n",
    "source = MesoPred.ConDict[tracer_category]['structure-abbrev'][tracer_num]\n",
    "A = ClfResults_ridge[tracer_category]['y_actual'][:,tracer_num]\n",
    "B = ClfResults_ridge[tracer_category]['y_preds'][:,tracer_num]\n",
    "A2 = ClfResults_ridge[tracer_category]['binary_patterns'][:,tracer_num]\n",
    "B2 = ClfResults_ridge[tracer_category]['pred binary_patterns'][:,tracer_num]\n",
    "print tracer_category, source \n",
    "\n",
    "tracer_category = other_scores[0][0] \n",
    "tracer_num = int(other_scores[0][1])\n",
    "print tracer_category, MesoPred.ConDict[tracer_category]['structure-abbrev'][0]\n",
    "A = ClfResults_ridge[other_scores[0][0]]['y_actual'][:,int(other_scores[0][1])]\n",
    "B = ClfResults_ridge[other_scores[0][0]]['y_preds'][:,int(other_scores[0][1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP_25 = PL.BrainPlotter(resolution = 25)\n",
    "BP_10 = PL.BrainPlotter(resolution = 10)\n",
    "source = MesoPred.ConDict[tracer_category]['structure-abbrev'][tracer_num]\n",
    "BP_25.fit(projection = A, chosen_indices = MesoPred.params['remaining_indices'],\n",
    "          projection2 = B)\n",
    "BP_10.fit(projection = A, chosen_indices = MesoPred.params['remaining_indices'],\n",
    "          projection2 = B)\n",
    "BP_25.plot_slice(savefile = 'figures/brain slice unionized {} {}.jpg'.format(tracer_category,source))\n",
    "BP_10.plot_flatmap(savefile = 'figures/flatmap_unionized {} {}.jpg'.format(tracer_category,source))\n",
    "BP_25.plot_slice(savefile = 'paper1_figures/brain_slice_unionized_{}_{}.eps'.format(tracer_category,source))\n",
    "BP_10.plot_flatmap(savefile = 'paper1_figures/flatmap_unionized_{}_{}.eps'.format(tracer_category,source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = ClfResults_ridge[other_scores[0][0]]['binary_patterns'][:,int(other_scores[0][1])]\n",
    "B2 = ClfResults_ridge[other_scores[0][0]]['pred binary_patterns'][:,int(other_scores[0][1])]\n",
    "BP_25 = PL.BrainPlotter(resolution = 25)\n",
    "BP_10 = PL.BrainPlotter(resolution = 10)\n",
    "BP_25.fit(projection = A2, chosen_indices = MesoPred.params['remaining_indices'])\n",
    "BP_10.fit(projection = A2, chosen_indices = MesoPred.params['remaining_indices'], projection2 = B2)\n",
    "#BP_25.plot_slice(savefile = 'figures/brain_slice_binarized_{}_{}.jpg'.format(tracer_category,source))#BP_10.plot_flatmap(savefile = 'figures/flatmap_binarized_{}_{}.jpg'.format(tracer_category,source), \n",
    "#                   mode = 'binary')\n",
    "BP_25.plot_slice(savefile = 'paper1_figures/brain_slice binarized_{}_{}.eps'.format(tracer_category,source))\n",
    "BP_10.plot_flatmap(savefile = 'paper1_figures/flatmap_binarized_{}_{}.eps'.format(tracer_category,source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Enrichment Test!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import numpy2ri\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "ro.numpy2ri.activate()\n",
    "\n",
    "ridge_params = {'alpha': [1,10,100,250,500,1000],\n",
    "                     'fit_intercept' : [True], 'normalize' : [False]}\n",
    "ridge_mdl = GridSearchCV(Ridge(), param_grid = ridge_params, \n",
    "                                 scoring = 'neg_mean_squared_error', \n",
    "                                 cv = 3, n_jobs = -1)\n",
    "stability_selection = RandomizedLasso(normalize = False)\n",
    "scaler              = StandardScaler()\n",
    "pipeline            = Pipeline([('scaler', scaler), ('stability_selection', stability_selection)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real        = ClfResults_ridge['Cux2-IRES-Cre']['y_actual']\n",
    "AltGoDict_new = {}\n",
    "AltGoDict_new['Cux2-IRES-Cre'] = {}\n",
    "for tracer in range(len(ClfResults_ridge['Cux2-IRES-Cre']['y_actual'][0])):\n",
    "    AltGoDict_new['Cux2-IRES-Cre'][tracer] = {}\n",
    "    y_meas = ClfResults_ridge['Cux2-IRES-Cre']['y_actual'][:,tracer]\n",
    "    for permutation in range(5):\n",
    "\n",
    "        red = 0\n",
    "        while red == 0:\n",
    "            y_shuffle = np.random.permutation(y_meas)\n",
    "            red =  np.sum(y_shuffle - y_meas)\n",
    "        \n",
    "        pipeline.fit(ClfResults_ridge['Cux2-IRES-Cre']['Gene Expression'], y_shuffle)\n",
    "        tmp = pipeline.get_params()['stability_selection'].get_support()\n",
    "        stability_hits = [MesoPred.params['Gene Ids'][i] for i, x in enumerate(tmp) if x]   \n",
    "        \n",
    "        ridge_mdl.fit(ClfResults_ridge['Cux2-IRES-Cre']['Gene Expression'], y_shuffle)\n",
    "        top_sur_genes = np.argsort(ridge_mdl.best_estimator_.coef_)[::-1]\n",
    "        ridge_hits = [MesoPred.params['Gene Ids'][i] for i, x in enumerate(top_sur_genes) if x]\n",
    "\n",
    "        ol_positions = [id2 for id1,val1 in enumerate(stability_hits) for id2,val2 in enumerate(ridge_hits) if val1==val2]\n",
    "        gene_consensus = [ridge_hits[val] for val in ol_positions if val <= len(stability_hits) and ridge_hits[val] is not None]        \n",
    "        \n",
    "        MGP = ro.r('''\n",
    "                GOenrichment <-function(GeneList){\n",
    "                    source(\"http://bioconductor.org/biocLite.R\")\n",
    "                    lib_path = \"~/R/x86_64-pc-linux-gnu-library/3.2/\"\n",
    "                    lib_path_2 = \"~/anaconda2/lib/R/library/org.Mm.eg.db\"\n",
    "                    #biocLite(\"ALL\")\n",
    "                    #biocLite(\"GOstats\", lib = lib_path)\n",
    "                    #biocLite(\"Category\", lib = lib_path)\n",
    "                    #biocLite(\"genefilter\", lib = lib_path)\n",
    "                    #biocLite(\"org.Mm.eg.db\", lib = lib_path_2)\n",
    "                    #biocLite(\"gage\", lib = lib_path)\n",
    "                    #biocLite(pkgs=c(\"Biobase\", \"IRanges\", \"AnnotationDbi\"),\n",
    "                     #   suppressUpdates=FALSE,\n",
    "                      #  suppressAutoUpdate=FALSE,\n",
    "                       # siteRepos=character(),\n",
    "                        #ask=TRUE, lib= lib_path)\n",
    "                    #install.packages(\"RSQLite\")\n",
    "                    #install.packages(\"devtools\")\n",
    "                    #require(devtools)\n",
    "                    #library(\"RSQLite\")\n",
    "                    #library(\"gage\")\n",
    "                    #library(\"genefilter\")\n",
    "                    #library(\"org.Mm.eg.db\")\n",
    "                    library(DBI)\n",
    "                    library(\"GO.db\")\n",
    "                    library(\"GOstats\")\n",
    "                    library(\"Category\")\n",
    "                    library(\"annotate\")\n",
    "                    data(ALL, package=\"ALL\")\n",
    "\n",
    "                    hgCutoff <- 0.05\n",
    "\n",
    "                    params <- new(\"GOHyperGParams\",\n",
    "                           geneIds = GeneList,\n",
    "                           universeGeneIds = NULL,\n",
    "                           annotation = \"org.Mm.eg.db\",\n",
    "                           ontology = \"CC\",\n",
    "                           pvalueCutoff = hgCutoff,\n",
    "                           conditional = FALSE,\n",
    "                           testDirection = \"over\")\n",
    "                    CC <- hyperGTest(params)\n",
    "                    sumCC <- data.frame(summary(CC))\n",
    "                    sumCC <- subset(sumCC, select=c(\"Term\"))\n",
    "\n",
    "                    foo <- vector(mode=\"list\", length = 3)\n",
    "                    #foo[[1]] <- sumBP\n",
    "                    #foo[[2]] <- sumMF\n",
    "                    foo[[3]] <- sumCC\n",
    "\n",
    "                    return(foo)\n",
    "                }''')\n",
    "        r_getname = ro.globalenv['GOenrichment']\n",
    "        verdict   = r_getname(gene_consensus)\n",
    "        temp_list = np.asarray(verdict[2])[0]\n",
    "        another_tmp = [element for element in temp_list if 'synap' in element or 'neur' in element]\n",
    "        AltGoDict_new['Cux2-IRES-Cre'][tracer][permutation] = another_tmp\n",
    "        pk.dump(AltGoDict_new, open('ontology_permutations/results.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as ro\n",
    "AltGoDict2 = {}\n",
    "AltGoDict2['Cux2-IRES-Cre'] = {}\n",
    "gene_consensus = pk.load(open('paper1_figures/gene_consensus.pkl','rb'))     \n",
    "for idx,gene_set in enumerate(gene_consensus['Cux2-IRES-Cre']):\n",
    "    print idx\n",
    "    MGP = ro.r('''\n",
    "            GOenrichment <-function(GeneList){\n",
    "                source(\"http://bioconductor.org/biocLite.R\")\n",
    "                lib_path = \"~/R/x86_64-pc-linux-gnu-library/3.2/\"\n",
    "                lib_path_2 = \"~/anaconda2/lib/R/library/org.Mm.eg.db\"\n",
    "                #biocLite(\"ALL\")\n",
    "                #biocLite(\"GOstats\", lib = lib_path)\n",
    "                #biocLite(\"Category\", lib = lib_path)\n",
    "                #biocLite(\"genefilter\", lib = lib_path)\n",
    "                #biocLite(\"org.Mm.eg.db\", lib = lib_path_2)\n",
    "                #biocLite(\"gage\", lib = lib_path)\n",
    "                #biocLite(pkgs=c(\"Biobase\", \"IRanges\", \"AnnotationDbi\"),\n",
    "                 #   suppressUpdates=FALSE,\n",
    "                  #  suppressAutoUpdate=FALSE,\n",
    "                   # siteRepos=character(),\n",
    "                    #ask=TRUE, lib= lib_path)\n",
    "                #install.packages(\"RSQLite\")\n",
    "                #install.packages(\"devtools\")\n",
    "                #require(devtools)\n",
    "                #library(\"RSQLite\")\n",
    "                #library(\"gage\")\n",
    "                #library(\"genefilter\")\n",
    "                #library(\"org.Mm.eg.db\")\n",
    "                library(DBI)\n",
    "                library(\"GO.db\")\n",
    "                library(\"GOstats\")\n",
    "                library(\"Category\")\n",
    "                library(\"annotate\")\n",
    "                data(ALL, package=\"ALL\")\n",
    "\n",
    "                hgCutoff <- 0.05\n",
    "\n",
    "                params <- new(\"GOHyperGParams\",\n",
    "                       geneIds = GeneList,\n",
    "                       universeGeneIds = NULL,\n",
    "                       annotation = \"org.Mm.eg.db\",\n",
    "                       ontology = \"CC\",\n",
    "                       pvalueCutoff = hgCutoff,\n",
    "                       conditional = FALSE,\n",
    "                       testDirection = \"over\")\n",
    "                CC <- hyperGTest(params)\n",
    "                sumCC <- data.frame(summary(CC))\n",
    "                sumCC <- subset(sumCC, select=c(\"Term\"))\n",
    "\n",
    "                foo <- vector(mode=\"list\", length = 3)\n",
    "                #foo[[1]] <- sumBP\n",
    "                #foo[[2]] <- sumMF\n",
    "                foo[[3]] <- sumCC\n",
    "\n",
    "                return(foo)\n",
    "            }''')\n",
    "    r_getname = ro.globalenv['GOenrichment']\n",
    "    verdict   = r_getname(gene_set)\n",
    "    temp_list = np.asarray(verdict[2])[0]\n",
    "    another_tmp = [element for element in temp_list if 'synap' in element or 'neur' in element]\n",
    "    AltGoDict2['Cux2-IRES-Cre'][idx] = another_tmp\n",
    "    pk.dump(AltGoDict2, open('ontology_permutations/results_actual.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AltGoDict_new = pk.load(open('ontology_permutations/results.pkl','rb'))\n",
    "#AltGoDict2 = pk.load(open('ontology_permutations/results_actual.pkl','rb'))\n",
    "\n",
    "ontology_comparison = []\n",
    "pval = []\n",
    "for tracer in AltGoDict_new['Cux2-IRES-Cre'].keys():\n",
    "    num_hits_pert = [len(surrogate) for surrogate in AltGoDict_new['Cux2-IRES-Cre'][tracer].values()]\n",
    "    num_hits_original = AltGoDict2['Cux2-IRES-Cre'][tracer]\n",
    "    pval.append(len([hits for hits in num_hits_pert if hits > len(num_hits_original)])/5.0)\n",
    "    #print tracer, pval\n",
    "    ontology_comparison.append((len(num_hits_original), np.median(num_hits_pert)))\n",
    "ontology_comparison = np.asarray(ontology_comparison)    \n",
    "print len([val for val in pval if val > 0.05]), 1.0*len(ontology_comparison)\n",
    "print ontology_comparison.shape\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_tick_params(labelsize = 18)\n",
    "ax.yaxis.set_tick_params(labelsize = 18)\n",
    "plt.scatter(ontology_comparison[:,0],ontology_comparison[:,1])\n",
    "plt.plot((0,45),(0,45))\n",
    "plt.xlabel('actual', fontsize = 18)\n",
    "plt.ylabel('permutated', fontsize = 18)\n",
    "plt.savefig('paper1_figures/ontology_comparison.eps')\n",
    "plt.title('Comparison between actual and permutated ontology hits for Cux2-IRES-Cre', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.listdir('../25 3 2019/'):\n",
    "    if os.path.islink(path) is True:\n",
    "        #call(['ln','-s','../25 3 2019/'+ path, path])\n",
    "        os.unlink(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
